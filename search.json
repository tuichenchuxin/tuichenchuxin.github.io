[{"categories":null,"content":"https://yeasy.gitbook.io/docker_practice/\n使用 dockerFile 创建镜像 FROM nginx RUN echo '\u003ch1\u003eHello, Docker!\u003c/h1\u003e' \u003e /usr/share/nginx/html/index.html 容器的使用 ","description":"","tags":null,"title":"Docker","uri":"/posts/docker/"},{"categories":null,"content":"构建 yat 下载源码\ngit clone https://gitee.com/opengauss/Yat.git 构建 yat\ncd Yat/yat-master chmod +x gradlew ./gradlew pack cd pkg chmod +x install ./install -F 根据源码中的 dockerFile 构建 dockerImage\n使用 yat 测试 测试 shardingSphere proxy 利用构建的 yat image 运行相关测试 需要挂在到对应目录\ndocker run --name yat0 -i -t -v /Users/chenchuxin/Documents/GitHub/Yat/openGaussBase:/root/openGaussBase -w /root/openGaussBase --entrypoint=bash --privileged=true yat-v1 修改 yat 项目 openGaussBase/conf 下的 configure.yml 文件\nyat.limit.case.size.max: '200K' yat.limit.case.count.max: 100000 yat.limit.case.depth.max: 10 yat.limit.case.name.pattern: .* 修改 yat 项目 openGaussBase/conf 下的 nodes.yml 文件\ndefault: host: 'host.docker.internal' db: url: 'jdbc:opengauss://host.docker.internal:3307/sharding_db?loggerLevel=OFF' driver: 'org.opengauss.Driver' username: 'root' password: 'root' port: 3307 name: 'sharding_db' ssh: port: 22 username: root password: '********' 创建 conf/env.sh\ntouch conf/env.sh 在 openGaussBase/schedule 目录创建 schedule.schd 文件，增加你需要测试的 case\ntest: SQL/DDL/view/Opengauss_Function_DDL_View_Case0034 进入 docker bash 模式 运行 yat suite\n[+] [2022-06-22 09:06:15] [05.394 s] [v] SQL/DDL/view/Opengauss_Function_DDL_View_Case0034 .... : ok ################# Testing Result 1/1 Using Time PT5.46011S At 2022-06-22 09:06:20 ################## Run test suite finished 也可能出现相关异常，可参考 https://gitee.com/opengauss/Yat/blob/master/yat-master/docs/index.md#yat-quick-start 来解决\n","description":"","tags":null,"title":"Add Yat Test for ShardingSphere","uri":"/posts/add-yat-test-for-shardingsphere/"},{"categories":null,"content":"https://zhuanlan.zhihu.com/p/515688555\nmac 开发环境启动 galaxysql https://hub.docker.com/r/polardbx/polardb-x\ndocker pull polardbx/polardb-x docker run -d --name some-dn-and-gms --env mode=dev -p 4886:4886 -p 32886:32886 polardbx/polardb-x docker exec -it 41d8a027 bash mysql -h127.0.0.1 -P4886 -uroot -padmin -D polardbx_meta_db_polardbx -e \"select passwd_enc from storage_info where inst_kind=2\" 获取密码后修改 server.properties\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 serverPort=8528 managerPort=3406 rpcPort=9090 charset=utf-8 processors=4 processorHandler=16 processorKillExecutor=128 timerExecutor=8 managerExecutor=256 serverExecutor=1024 idleTimeout= trustedIps=127.0.0.1 slowSqlTime=1000 maxConnection=20000 allowManagerLogin=1 allowCrossDbQuery=true galaxyXProtocol=1 metaDbAddr=127.0.0.1:4886 metaDbXprotoPort=32886 metaDbUser=my_polarx # 前文查看的存储节点密码 metaDbPasswd=qEJWtCdgsOIie4j4mKP2Bvg2dsFHzdIhTaqMiq86N1QQU1HHL7olKb60pxz5hp/4 #?? E2+jB0*0\u0026gM9)9$4+6)E4@1$lO9%G8+jA4_ metaDbName=polardbx_meta_db_polardbx instanceId=polardbx-polardbx 注释掉 CobarServer.java 中 tryStartCdcManager(); 代码\n启动配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003ccomponent name=\"ProjectRunConfigurationManager\"\u003e \u003cconfiguration default=\"false\" name=\"TddlLauncher\" type=\"Application\" factoryName=\"Application\" singleton=\"false\" nameIsGenerated=\"true\"\u003e \u003cenvs\u003e \u003cenv name=\"dnPasswordKey\" value=\"asdf1234ghjk5678\" /\u003e \u003c/envs\u003e \u003coption name=\"MAIN_CLASS_NAME\" value=\"com.alibaba.polardbx.server.TddlLauncher\" /\u003e \u003cmodule name=\"polardbx-server\" /\u003e \u003coption name=\"VM_PARAMETERS\" value=\"-Dserver.conf=$PROJECT_DIR$/polardbx-server/src/main/conf/server.properties\" /\u003e \u003cextension name=\"coverage\"\u003e \u003cpattern\u003e \u003coption name=\"PATTERN\" value=\"com.alibaba.polardbx.server.*\" /\u003e \u003coption name=\"ENABLED\" value=\"true\" /\u003e \u003c/pattern\u003e \u003c/extension\u003e \u003cmethod v=\"2\"\u003e \u003coption name=\"Make\" enabled=\"true\" /\u003e \u003c/method\u003e \u003c/configuration\u003e \u003c/component\u003e 连接 polar-dbx cn\nmysql -h127.0.0.1 -P8528 -upolardbx_root -p123456 polardb-x debug ddl create ddl 一直不能成功原来是因为，docker 镜像中没有启动 cdc，DDL 流程中涉及到 notify cdc，所以注释 CdcManager.notifyDdl 方法中的代码可以执行成功。 这篇文档写得挺好，说明了 ddl 执行的流程 https://zhuanlan.zhihu.com/p/515688555\n","description":"","tags":null,"title":"Polar Db","uri":"/posts/polar-db/"},{"categories":null,"content":"Step 1: 克隆项目\nStep 2: 添加新的远程仓库 为了修改他人 Fork 的仓库，你需要将其添加到自己的远程仓库列表中\n$ git remote add sirmin https://github.com/SirMin/shardingsphere.git 现在，当你执行 git remote -v 指令时，就可以看到他人 Fork 的仓库，出现在你的远程仓库列表中：\n% git remote -v origin\thttps://github.com/tuichenchuxin/shardingsphere.git (fetch) origin\thttps://github.com/tuichenchuxin/shardingsphere.git (push) sirmin\thttps://github.com/SirMin/shardingsphere.git (fetch) sirmin\thttps://github.com/SirMin/shardingsphere.git (push) upstream\thttps://github.com/apache/shardingsphere.git (fetch) upstream\thttps://github.com/apache/shardingsphere.git (push) Step 3: 拉取新的远程仓库\n$ git fetch sirmin Step 4: 切换到对应的分支 你需要确认一下，贡献者提出 Pull Request 时所用的分支（如果你不确定他们使用的哪个分支，请看 Pull Request 顶部的信息）：\n在本地，给该分支起一个不重复的名字，例如 EvanOne0616-patch，然后切换到贡献者提出 Pull Request 所用的分支：\n$ git checkout -b sirmin-patch sirmin/sirmin/resultSet Step 5: 提交修改，推送远程\n$ git commit -m \"Fix the wrong spelling of the word\" $ git push sirmin HEAD:sirmin/resultSet ","description":"","tags":null,"title":"ModifyPr","uri":"/posts/modifypr/"},{"categories":null,"content":"docker pull registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g docker run --privileged --restart=always --name oracle_11g -p 1521:1521 -d registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g docker exec -it 容器ID /bin/bash source /home/oracle/.bash_profile sqlplus nologconnect as sysdba 1 2 3 4 create user oracle identified by oracle#123; alter user system identified by system; alter user system identified by 123456; grant connect,resource,dba to oracle; 参考：https://baijiahao.baidu.com/s?id=1709232831349390844\u0026wfr=spider\u0026for=pc\n","description":"","tags":null,"title":"mac docker 安装 oracle 11g","uri":"/posts/installoracle11g/"},{"categories":null,"content":"Freemarker freemarker 是一款开源的模版引擎，可以基于模版方便的生成结果。 https://freemarker.apache.org/\nFreemarker 的使用 编写 ftl 模版 以生成 postgres 查询的 sql 语句为例 编写 delete.ftl 文件，${} 中的字段是参数\n1 DROP TABLE IF EXISTS ${schema}.${name}; 当然实际使用中的模版可能复杂的多，以部分创建表模版为例 我们可以在模版中使用 import 引入其它模版 使用 assign 设置变量 使用 if, list 等 使用 ?? 判断是否为空，使用 !false 如果为空，默认 false\n\u003c#import \"../../macro/constraints.ftl\" as CONSTRAINTS\u003e \u003c#assign with_clause = false\u003e \u003c#if fillfactor!false || parallel_workers!false || toast_tuple_target!false || (autovacuum_custom!false \u0026\u0026 add_vacuum_settings_in_sql!false) || autovacuum_enabled == 't' || autovacuum_enabled == 'f' || (toast_autovacuum!false \u0026\u0026 add_vacuum_settings_in_sql!false) || toast_autovacuum_enabled == 't' || toast_autovacuum_enabled == 'f' \u003e \u003c#assign with_clause = true\u003e \u003c/#if\u003e \u003c#list columns as c \u003e 其它模版使用可以参考 https://freemarker.apache.org/docs/dgui_template.html\njava 使用 freemarker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @NoArgsConstructor(access = AccessLevel.PRIVATE) public final class FreemarkerManager { private static final FreemarkerManager INSTANCE = new FreemarkerManager(); private final Configuration templateConfig = createTemplateConfiguration(); /** * Get freemarker manager instance. * * @return freemarker manager instance */ public static FreemarkerManager getInstance() { return INSTANCE; } @SneakyThrows private Configuration createTemplateConfiguration() { Configuration result = new Configuration(Configuration.VERSION_2_3_31); result.setDirectoryForTemplateLoading(new File(Objects.requireNonNull(FreemarkerManager.class.getClassLoader().getResource(\"template\")).getFile())); result.setDefaultEncoding(\"UTF-8\"); return result; } /** * Get sql from template. * * @param data data * @param path path * @return sql */ @SneakyThrows public static String getSqlFromTemplate(final Map\u003cString, Object\u003e data, final String path) { Template template = FreemarkerManager.getInstance().templateConfig.getTemplate(path); try (StringWriter result = new StringWriter()) { template.process(data, result); return result.toString(); } } } ","description":"","tags":null,"title":"Freemarker 的使用","uri":"/posts/use_free_marker/"},{"categories":null,"content":"下载源码 https://github.com/postgres/pgadmin4\n安装环境 brew install node brew install yarn cd runtime yarn install node_modules/nw/nwjs/nwjs.app/Contents/MacOS/nwjs . sudo mkdir \"/var/log/pgadmin\" sudo chmod a+wrx \"/var/log/pgadmin\" sudo mkdir \"/var/lib/pgadmin\" sudo chmod a+wrx \"/var/lib/pgadmin\" pip install --upgrade pip pip install psycopg2-binary make install-node 最后运行 pgAdmin4.py 过程中会有一些问题，参考 https://github.com/postgres/pgadmin4 readme. 和 stack overflow\n","description":"","tags":null,"title":"HowToDebugPgAdmin4","uri":"/posts/howtodebugpgadmin4/"},{"categories":null,"content":"PgAmdin4 展示 DDL 语句 通过 PgAdmin4 可以获取 table 的 DDL 语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- Table: public.t_order_0 -- DROP TABLE IF EXISTS public.t_order_0; CREATE TABLE IF NOT EXISTS public.t_order_0 ( order_id integer NOT NULL, user_id integer NOT NULL, status character varying(45) COLLATE pg_catalog.\"default\", CONSTRAINT t_order_0_pkey PRIMARY KEY (order_id) ) TABLESPACE pg_default; ALTER TABLE IF EXISTS public.t_order_0 OWNER to postgres; COMMENT ON TABLE public.t_order_0 IS 'haha'; COMMENT ON COLUMN public.t_order_0.order_id IS 'haha'; PgAdmin4 是如何展示对应的 DDL 语句的呢 https://github.com/postgres/pgadmin4 翻阅源码发现 DDL 语句的展示，主要是通过以下步骤来获取 SQL 语句的。\n查询表基础信息（区分 pg 不同版本） 获取相关权限信息 查询列相关信息 检查 of_type 和 继承表，如果存在需要获取 获取该表的所有列信息 对列做格式化 查询 constriant 信息，并添加到 列上 检查 table is partitions 查询 index 信息 查询 ROW SECURITY POLICY 查询 Triggers 查询 Rules 相关代码如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def sql(self, gid, sid, did, scid, tid): \"\"\" This function will creates reverse engineered sql for the table object Args: gid: Server Group ID sid: Server ID did: Database ID scid: Schema ID tid: Table ID \"\"\" main_sql = [] status, res = self._fetch_table_properties(did, scid, tid) if not status: return res if len(res['rows']) == 0: return gone(gettext(self.not_found_error_msg())) data = res['rows'][0] return BaseTableView.get_reverse_engineered_sql( self, did=did, scid=scid, tid=tid, main_sql=main_sql, data=data, add_not_exists_clause=True) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_reverse_engineered_sql(self, **kwargs): \"\"\" This function will creates reverse engineered sql for the table object Args: kwargs \"\"\" did = kwargs.get('did') scid = kwargs.get('scid') tid = kwargs.get('tid') main_sql = kwargs.get('main_sql') data = kwargs.get('data') json_resp = kwargs.get('json_resp', True) diff_partition_sql = kwargs.get('diff_partition_sql', False) if_exists_flag = kwargs.get('add_not_exists_clause', False) # Table \u0026 Schema declaration so that we can use them in child nodes schema = data['schema'] table = data['name'] is_partitioned = 'is_partitioned' in data and data['is_partitioned'] # Get Reverse engineered sql for Table self._get_resql_for_table(did, scid, tid, data, json_resp, main_sql, add_not_exists_clause=if_exists_flag) # Get Reverse engineered sql for Table self._get_resql_for_index(did, tid, main_sql, json_resp, schema, table, add_not_exists_clause=if_exists_flag) # Get Reverse engineered sql for ROW SECURITY POLICY self._get_resql_for_row_security_policy(scid, tid, json_resp, main_sql, schema, table) # Get Reverse engineered sql for Triggers self._get_resql_for_triggers(tid, json_resp, main_sql, schema, table) # Get Reverse engineered sql for Compound Triggers self._get_resql_for_compound_triggers(tid, main_sql, schema, table) # Get Reverse engineered sql for Rules self._get_resql_for_rules(tid, main_sql, table, json_resp) # Get Reverse engineered sql for Partitions partition_main_sql = \"\" if is_partitioned: sql = render_template(\"/\".join([self.partition_template_path, self._NODES_SQL]), scid=scid, tid=tid) status, rset = self.conn.execute_2darray(sql) if not status: return internal_server_error(errormsg=rset) self._get_resql_for_partitions(data, rset, json_resp, diff_partition_sql, main_sql, did) sql = '\\n'.join(main_sql) if not json_resp: return sql, partition_main_sql return ajax_response(response=sql.strip('\\n')) pgAdmin 展示表结构反向 SQL 执行了哪些 SQL 语句呢？ table propeties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 SELECT rel.oid, rel.relname AS name, rel.reltablespace AS spcoid,rel.relacl AS relacl_str, (CASE WHEN length(spc.spcname::text) \u003e 0 OR rel.relkind = 'p' THEN spc.spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END) as spcname, (CASE rel.relreplident WHEN 'd' THEN 'default' WHEN 'n' THEN 'nothing' WHEN 'f' THEN 'full' WHEN 'i' THEN 'index' END) as replica_identity, (select nspname FROM pg_catalog.pg_namespace WHERE oid = 2200::oid ) as schema, pg_catalog.pg_get_userbyid(rel.relowner) AS relowner, rel.relkind, (CASE WHEN rel.relkind = 'p' THEN true ELSE false END) AS is_partitioned, rel.relhassubclass, rel.reltuples::bigint, des.description, con.conname, con.conkey, EXISTS(select 1 FROM pg_catalog.pg_trigger JOIN pg_catalog.pg_proc pt ON pt.oid=tgfoid AND pt.proname='logtrigger' JOIN pg_catalog.pg_proc pc ON pc.pronamespace=pt.pronamespace AND pc.proname='slonyversion' WHERE tgrelid=rel.oid) AS isrepl, (SELECT count(*) FROM pg_catalog.pg_trigger WHERE tgrelid=rel.oid AND tgisinternal = FALSE) AS triggercount, (SELECT ARRAY(SELECT CASE WHEN (nspname NOT LIKE 'pg\\_%') THEN pg_catalog.quote_ident(nspname)||'.'||pg_catalog.quote_ident(c.relname) ELSE pg_catalog.quote_ident(c.relname) END AS inherited_tables FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid ORDER BY inhseqno)) AS coll_inherits, (SELECT count(*) FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid) AS inherited_tables_cnt, (CASE WHEN rel.relpersistence = 'u' THEN true ELSE false END) AS relpersistence, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'fillfactor=([0-9]*)') AS fillfactor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'parallel_workers=([0-9]*)') AS parallel_workers, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'toast_tuple_target=([0-9]*)') AS toast_tuple_target, (substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS autovacuum_enabled, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS autovacuum_freeze_table_age, (substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS toast_autovacuum_enabled, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS toast_autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS toast_autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS toast_autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS toast_autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS toast_autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS toast_autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS toast_autovacuum_freeze_table_age, rel.reloptions AS reloptions, tst.reloptions AS toast_reloptions, rel.reloftype, CASE WHEN typ.typname IS NOT NULL THEN (select pg_catalog.quote_ident(nspname) FROM pg_catalog.pg_namespace WHERE oid = 2200::oid )||'.'||pg_catalog.quote_ident(typ.typname) ELSE typ.typname END AS typname, typ.typrelid AS typoid, rel.relrowsecurity as rlspolicy, rel.relforcerowsecurity as forcerlspolicy, (CASE WHEN rel.reltoastrelid = 0 THEN false ELSE true END) AS hastoasttable, (SELECT pg_catalog.array_agg(provider || '=' || label) FROM pg_catalog.pg_seclabels sl1 WHERE sl1.objoid=rel.oid AND sl1.objsubid=0) AS seclabels, (CASE WHEN rel.oid \u003c= 13756::oid THEN true ElSE false END) AS is_sys_table -- Added for partition table , (CASE WHEN rel.relkind = 'p' THEN pg_catalog.pg_get_partkeydef(16410::oid) ELSE '' END) AS partition_scheme FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=rel.oid AND des.objsubid=0 AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND NOT rel.relispartition AND rel.oid = 16410::oid ORDER BY rel.relname; 表总数 'SELECT COUNT(*)::text FROM public.t_order_1;' 权限 SELECT 'relacl' as deftype, COALESCE(gt.rolname, 'PUBLIC') grantee, g.rolname grantor, pg_catalog.array_agg(privilege_type) as privileges, pg_catalog.array_agg(is_grantable) as grantable FROM (SELECT d.grantee, d.grantor, d.is_grantable, CASE d.privilege_type WHEN 'CONNECT' THEN 'c' WHEN 'CREATE' THEN 'C' WHEN 'DELETE' THEN 'd' WHEN 'EXECUTE' THEN 'X' WHEN 'INSERT' THEN 'a' WHEN 'REFERENCES' THEN 'x' WHEN 'SELECT' THEN 'r' WHEN 'TEMPORARY' THEN 'T' WHEN 'TRIGGER' THEN 't' WHEN 'TRUNCATE' THEN 'D' WHEN 'UPDATE' THEN 'w' WHEN 'USAGE' THEN 'U' ELSE 'UNKNOWN' END AS privilege_type FROM (SELECT rel.relacl FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) acl, (SELECT (d).grantee AS grantee, (d).grantor AS grantor, (d).is_grantable AS is_grantable, (d).privilege_type AS privilege_type FROM (SELECT aclexplode(rel.relacl) as d FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) a ORDER BY privilege_type) d ) d LEFT JOIN pg_catalog.pg_roles g ON (d.grantor = g.oid) LEFT JOIN pg_catalog.pg_roles gt ON (d.grantee = gt.oid) GROUP BY g.rolname, gt.rolname reverse engine for table\nSELECT 'relacl' as deftype, COALESCE(gt.rolname, 'PUBLIC') grantee, g.rolname grantor, pg_catalog.array_agg(privilege_type) as privileges, pg_catalog.array_agg(is_grantable) as grantable FROM (SELECT d.grantee, d.grantor, d.is_grantable, CASE d.privilege_type WHEN 'CONNECT' THEN 'c' WHEN 'CREATE' THEN 'C' WHEN 'DELETE' THEN 'd' WHEN 'EXECUTE' THEN 'X' WHEN 'INSERT' THEN 'a' WHEN 'REFERENCES' THEN 'x' WHEN 'SELECT' THEN 'r' WHEN 'TEMPORARY' THEN 'T' WHEN 'TRIGGER' THEN 't' WHEN 'TRUNCATE' THEN 'D' WHEN 'UPDATE' THEN 'w' WHEN 'USAGE' THEN 'U' ELSE 'UNKNOWN' END AS privilege_type FROM (SELECT rel.relacl FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) acl, (SELECT (d).grantee AS grantee, (d).grantor AS grantor, (d).is_grantable AS is_grantable, (d).privilege_type AS privilege_type FROM (SELECT aclexplode(rel.relacl) as d FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) a ORDER BY privilege_type) d ) d LEFT JOIN pg_catalog.pg_roles g ON (d.grantor = g.oid) LEFT JOIN pg_catalog.pg_roles gt ON (d.grantee = gt.oid) GROUP BY g.rolname, gt.rolname 获取列\nSELECT att.attname as name, att.atttypid, att.attlen, att.attnum, att.attndims, att.atttypmod, att.attacl, att.attnotnull, att.attoptions, att.attstattarget, att.attstorage, att.attidentity, pg_catalog.pg_get_expr(def.adbin, def.adrelid) AS defval, pg_catalog.format_type(ty.oid,NULL) AS typname, pg_catalog.format_type(ty.oid,att.atttypmod) AS displaytypname, pg_catalog.format_type(ty.oid,att.atttypmod) AS cltype, CASE WHEN ty.typelem \u003e 0 THEN ty.typelem ELSE ty.oid END as elemoid, (SELECT nspname FROM pg_catalog.pg_namespace WHERE oid = ty.typnamespace) as typnspname, ty.typstorage AS defaultstorage, description, pi.indkey, (SELECT count(1) FROM pg_catalog.pg_type t2 WHERE t2.typname=ty.typname) \u003e 1 AS isdup, CASE WHEN length(coll.collname::text) \u003e 0 AND length(nspc.nspname::text) \u003e 0 THEN pg_catalog.concat(pg_catalog.quote_ident(nspc.nspname),'.',pg_catalog.quote_ident(coll.collname)) ELSE '' END AS collspcname, EXISTS(SELECT 1 FROM pg_catalog.pg_constraint WHERE conrelid=att.attrelid AND contype='f' AND att.attnum=ANY(conkey)) As is_fk, (SELECT pg_catalog.array_agg(provider || '=' || label) FROM pg_catalog.pg_seclabels sl1 WHERE sl1.objoid=att.attrelid AND sl1.objsubid=att.attnum) AS seclabels, (CASE WHEN (att.attnum \u003c 1) THEN true ElSE false END) AS is_sys_column, (CASE WHEN (att.attidentity in ('a', 'd')) THEN 'i' WHEN (att.attgenerated in ('s')) THEN 'g' ELSE 'n' END) AS colconstype, (CASE WHEN (att.attgenerated in ('s')) THEN pg_catalog.pg_get_expr(def.adbin, def.adrelid) END) AS genexpr, tab.relname as relname, (CASE WHEN tab.relkind = 'v' THEN true ELSE false END) AS is_view_only, seq.* FROM pg_catalog.pg_attribute att JOIN pg_catalog.pg_type ty ON ty.oid=atttypid LEFT OUTER JOIN pg_catalog.pg_attrdef def ON adrelid=att.attrelid AND adnum=att.attnum LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=att.attrelid AND des.objsubid=att.attnum AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN (pg_catalog.pg_depend dep JOIN pg_catalog.pg_class cs ON dep.classid='pg_class'::regclass AND dep.objid=cs.oid AND cs.relkind='S') ON dep.refobjid=att.attrelid AND dep.refobjsubid=att.attnum LEFT OUTER JOIN pg_catalog.pg_index pi ON pi.indrelid=att.attrelid AND indisprimary LEFT OUTER JOIN pg_catalog.pg_collation coll ON att.attcollation=coll.oid LEFT OUTER JOIN pg_catalog.pg_namespace nspc ON coll.collnamespace=nspc.oid LEFT OUTER JOIN pg_catalog.pg_sequence seq ON cs.oid=seq.seqrelid LEFT OUTER JOIN pg_catalog.pg_class tab on tab.oid = att.attrelid WHERE att.attrelid = 16410::oid AND att.attnum \u003e 0 AND att.attisdropped IS FALSE ORDER BY att.attnum; SELECT t.main_oid, pg_catalog.ARRAY_AGG(t.typname) as edit_types FROM (SELECT pc.castsource AS main_oid, pg_catalog.format_type(tt.oid,NULL) AS typname FROM pg_catalog.pg_type tt JOIN pg_catalog.pg_cast pc ON tt.oid=pc.casttarget WHERE pc.castsource IN (23,1043) AND pc.castcontext IN ('i', 'a') UNION SELECT tt.typbasetype AS main_oid, pg_catalog.format_type(tt.oid,NULL) AS typname FROM pg_catalog.pg_type tt WHERE tt.typbasetype IN (23,1043) ) t GROUP BY t.main_oid; SELECT 'attacl' as deftype, COALESCE(gt.rolname, 'PUBLIC') grantee, g.rolname grantor, pg_catalog.array_agg(privilege_type order by privilege_type) as privileges, pg_catalog.array_agg(is_grantable) as grantable FROM (SELECT d.grantee, d.grantor, d.is_grantable, CASE d.privilege_type WHEN 'CONNECT' THEN 'c' WHEN 'CREATE' THEN 'C' WHEN 'DELETE' THEN 'd' WHEN 'EXECUTE' THEN 'X' WHEN 'INSERT' THEN 'a' WHEN 'REFERENCES' THEN 'x' WHEN 'SELECT' THEN 'r' WHEN 'TEMPORARY' THEN 'T' WHEN 'TRIGGER' THEN 't' WHEN 'TRUNCATE' THEN 'D' WHEN 'UPDATE' THEN 'w' WHEN 'USAGE' THEN 'U' ELSE 'UNKNOWN' END AS privilege_type FROM (SELECT attacl FROM pg_catalog.pg_attribute att WHERE att.attrelid = 16410::oid AND att.attnum = 1::int ) acl, (SELECT (d).grantee AS grantee, (d).grantor AS grantor, (d).is_grantable AS is_grantable, (d).privilege_type AS privilege_type FROM (SELECT pg_catalog.aclexplode(attacl) as d FROM pg_catalog.pg_attribute att WHERE att.attrelid = 16410::oid AND att.attnum = 1::int) a) d ) d LEFT JOIN pg_catalog.pg_roles g ON (d.grantor = g.oid) LEFT JOIN pg_catalog.pg_roles gt ON (d.grantee = gt.oid) GROUP BY g.rolname, gt.rolname ORDER BY grantee SELECT cls.oid, cls.relname as name, indnkeyatts as col_count, CASE WHEN length(spcname::text) \u003e 0 THEN spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END as spcname, CASE contype WHEN 'p' THEN desp.description WHEN 'u' THEN desp.description WHEN 'x' THEN desp.description ELSE des.description END AS comment, condeferrable, condeferred, conislocal, substring(pg_catalog.array_to_string(cls.reloptions, ',') from 'fillfactor=([0-9]*)') AS fillfactor FROM pg_catalog.pg_index idx JOIN pg_catalog.pg_class cls ON cls.oid=indexrelid LEFT OUTER JOIN pg_catalog.pg_tablespace ta on ta.oid=cls.reltablespace LEFT JOIN pg_catalog.pg_depend dep ON (dep.classid = cls.tableoid AND dep.objid = cls.oid AND dep.refobjsubid = '0' AND dep.refclassid=(SELECT oid FROM pg_catalog.pg_class WHERE relname='pg_constraint') AND dep.deptype='i') LEFT OUTER JOIN pg_catalog.pg_constraint con ON (con.tableoid = dep.refclassid AND con.oid = dep.refobjid) LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=cls.oid AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_description desp ON (desp.objoid=con.oid AND desp.objsubid = 0 AND desp.classoid='pg_constraint'::regclass) WHERE indrelid = 16410::oid AND contype='u' ORDER BY cls.relname SELECT c.oid, conname as name, relname, nspname, description as comment, pg_catalog.pg_get_expr(conbin, conrelid, true) as consrc, connoinherit, NOT convalidated as convalidated, conislocal FROM pg_catalog.pg_constraint c JOIN pg_catalog.pg_class cl ON cl.oid=conrelid JOIN pg_catalog.pg_namespace nl ON nl.oid=relnamespace LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=c.oid AND des.classoid='pg_constraint'::regclass) WHERE contype = 'c' AND conrelid = 16410::oid SELECT cls.oid, cls.relname as name, indnkeyatts as col_count, amname, CASE WHEN length(spcname::text) \u003e 0 THEN spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END as spcname, CASE contype WHEN 'p' THEN desp.description WHEN 'u' THEN desp.description WHEN 'x' THEN desp.description ELSE des.description END AS comment, condeferrable, condeferred, substring(pg_catalog.array_to_string(cls.reloptions, ',') from 'fillfactor=([0-9]*)') AS fillfactor, pg_catalog.pg_get_expr(idx.indpred, idx.indrelid, true) AS indconstraint FROM pg_catalog.pg_index idx JOIN pg_catalog.pg_class cls ON cls.oid=indexrelid LEFT OUTER JOIN pg_catalog.pg_tablespace ta on ta.oid=cls.reltablespace JOIN pg_catalog.pg_am am ON am.oid=cls.relam LEFT JOIN pg_catalog.pg_depend dep ON (dep.classid = cls.tableoid AND dep.objid = cls.oid AND dep.refobjsubid = '0' AND dep.refclassid=(SELECT oid FROM pg_catalog.pg_class WHERE relname='pg_constraint') AND dep.deptype='i') LEFT OUTER JOIN pg_catalog.pg_constraint con ON (con.tableoid = dep.refclassid AND con.oid = dep.refobjid) LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=cls.oid AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_description desp ON (desp.objoid=con.oid AND desp.objsubid = 0 AND desp.classoid='pg_constraint'::regclass) WHERE indrelid = 16410::oid AND contype='x' ORDER BY cls.relname Table 结束，接下来是 index\nSELECT DISTINCT ON(cls.relname) cls.oid, cls.relname as name, (SELECT (CASE WHEN count(i.inhrelid) \u003e 0 THEN true ELSE false END) FROM pg_inherits i WHERE i.inhrelid = cls.oid) as is_inherited FROM pg_catalog.pg_index idx JOIN pg_catalog.pg_class cls ON cls.oid=indexrelid JOIN pg_catalog.pg_class tab ON tab.oid=indrelid LEFT OUTER JOIN pg_catalog.pg_tablespace ta on ta.oid=cls.reltablespace JOIN pg_catalog.pg_namespace n ON n.oid=tab.relnamespace JOIN pg_catalog.pg_am am ON am.oid=cls.relam LEFT JOIN pg_catalog.pg_depend dep ON (dep.classid = cls.tableoid AND dep.objid = cls.oid AND dep.refobjsubid = '0' AND dep.refclassid=(SELECT oid FROM pg_catalog.pg_class WHERE relname='pg_constraint') AND dep.deptype='i') LEFT OUTER JOIN pg_catalog.pg_constraint con ON (con.tableoid = dep.refclassid AND con.oid = dep.refobjid) WHERE indrelid = 16410::OID AND conname is NULL ORDER BY cls.relname ROW SECURITY POLICY\n'SELECT pl.oid AS oid, pl.polname AS name FROM pg_catalog.pg_policy pl WHERE pl.polrelid\t= 16410 ORDER BY pl.polname;' trigger\n1 2 3 4 5 SELECT t.oid, t.tgname as name, t.tgenabled AS is_enable_trigger FROM pg_catalog.pg_trigger t WHERE NOT tgisinternal AND tgrelid = 16410::OID ORDER BY tgname; rules\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT rw.oid AS oid, rw.rulename AS name, CASE WHEN rw.ev_enabled != \\'D\\' THEN True ELSE False END AS enabled, rw.ev_enabled AS is_enable_rule FROM pg_catalog.pg_rewrite rw WHERE rw.ev_class = 16410 ORDER BY rw.rulename ","description":"","tags":null,"title":"PgAmdin4 展示 DDL 语句逻辑分析","uri":"/posts/analysispgamdin4ddl/"},{"categories":null,"content":"获取 postgres 的建表语句的几种方法 使用 pg_dump 可以使用 pg_dump 直接查看建表语句 以本机 docker 的 postgres 为例\ndocker run -it --rm postgres pg_dump -h host.docker.internal -p 5432 -U postgres -d demo_ds_0 -s -t t_order_0 结果展示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 -- -- PostgreSQL database dump -- -- Dumped from database version 14.2 (Debian 14.2-1.pgdg110+1) -- Dumped by pg_dump version 14.2 (Debian 14.2-1.pgdg110+1) SET statement_timeout = 0; SET lock_timeout = 0; SET idle_in_transaction_session_timeout = 0; SET client_encoding = 'UTF8'; SET standard_conforming_strings = on; SELECT pg_catalog.set_config('search_path', '', false); SET check_function_bodies = false; SET xmloption = content; SET client_min_messages = warning; SET row_security = off; SET default_tablespace = ''; SET default_table_access_method = heap; -- -- Name: t_order_0; Type: TABLE; Schema: public; Owner: postgres -- CREATE TABLE public.t_order_0 ( order_id integer NOT NULL, user_id integer NOT NULL, status character varying(45) ); ALTER TABLE public.t_order_0 OWNER TO postgres; -- -- Name: TABLE t_order_0; Type: COMMENT; Schema: public; Owner: postgres -- COMMENT ON TABLE public.t_order_0 IS 'haha'; -- -- Name: COLUMN t_order_0.order_id; Type: COMMENT; Schema: public; Owner: postgres -- COMMENT ON COLUMN public.t_order_0.order_id IS 'haha'; -- -- Name: t_order_0 t_order_0_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres -- ALTER TABLE ONLY public.t_order_0 ADD CONSTRAINT t_order_0_pkey PRIMARY KEY (order_id); -- -- PostgreSQL database dump complete -- 使用自定义函数 创建函数如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 CREATE OR REPLACE FUNCTION tabledef(oid) RETURNS text LANGUAGE sql STRICT AS $$ /* snatched from https://github.com/filiprem/pg-tools */ WITH attrdef AS ( SELECT n.nspname, c.relname, pg_catalog.array_to_string(c.reloptions || array(select 'toast.' || x from pg_catalog.unnest(tc.reloptions) x), ', ') as relopts, c.relpersistence, a.attnum, a.attname, pg_catalog.format_type(a.atttypid, a.atttypmod) as atttype, (SELECT substring(pg_catalog.pg_get_expr(d.adbin, d.adrelid, true) for 128) FROM pg_catalog.pg_attrdef d WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum AND a.atthasdef) as attdefault, a.attnotnull, (SELECT c.collname FROM pg_catalog.pg_collation c, pg_catalog.pg_type t WHERE c.oid = a.attcollation AND t.oid = a.atttypid AND a.attcollation \u003c\u003e t.typcollation) as attcollation, a.attidentity, a.attgenerated FROM pg_catalog.pg_attribute a JOIN pg_catalog.pg_class c ON a.attrelid = c.oid JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid LEFT JOIN pg_catalog.pg_class tc ON (c.reltoastrelid = tc.oid) WHERE a.attrelid = $1 AND a.attnum \u003e 0 AND NOT a.attisdropped ORDER BY a.attnum ), coldef AS ( SELECT attrdef.nspname, attrdef.relname, attrdef.relopts, attrdef.relpersistence, pg_catalog.format( '%I %s%s%s%s%s', attrdef.attname, attrdef.atttype, case when attrdef.attcollation is null then '' else pg_catalog.format(' COLLATE %I', attrdef.attcollation) end, case when attrdef.attnotnull then ' NOT NULL' else '' end, case when attrdef.attdefault is null then '' else case when attrdef.attgenerated = 's' then pg_catalog.format(' GENERATED ALWAYS AS (%s) STORED', attrdef.attdefault) when attrdef.attgenerated \u003c\u003e '' then ' GENERATED AS NOT_IMPLEMENTED' else pg_catalog.format(' DEFAULT %s', attrdef.attdefault) end end, case when attrdef.attidentity\u003c\u003e'' then pg_catalog.format(' GENERATED %s AS IDENTITY', case attrdef.attidentity when 'd' then 'BY DEFAULT' when 'a' then 'ALWAYS' else 'NOT_IMPLEMENTED' end) else '' end ) as col_create_sql FROM attrdef ORDER BY attrdef.attnum ), tabdef AS ( SELECT coldef.nspname, coldef.relname, coldef.relopts, coldef.relpersistence, string_agg(coldef.col_create_sql, E',\\n ') as cols_create_sql FROM coldef GROUP BY coldef.nspname, coldef.relname, coldef.relopts, coldef.relpersistence ) SELECT format( 'CREATE%s TABLE %I.%I%s%s%s;', case tabdef.relpersistence when 't' then ' TEMP' when 'u' then ' UNLOGGED' else '' end, tabdef.nspname, tabdef.relname, coalesce( (SELECT format(E'\\n PARTITION OF %I.%I %s\\n', pn.nspname, pc.relname, pg_get_expr(c.relpartbound, c.oid)) FROM pg_class c JOIN pg_inherits i ON c.oid = i.inhrelid JOIN pg_class pc ON pc.oid = i.inhparent JOIN pg_namespace pn ON pn.oid = pc.relnamespace WHERE c.oid = $1), format(E' (\\n %s\\n)', tabdef.cols_create_sql) ), case when tabdef.relopts \u003c\u003e '' then format(' WITH (%s)', tabdef.relopts) else '' end, coalesce(E'\\nPARTITION BY '||pg_get_partkeydef($1), '') ) as table_create_sql FROM tabdef $$; 通过 pgAdmin4 获取 抓包后，发现 pgAdmin4 实际查询的 sql 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 SELECT rel.oid, rel.relname AS name, rel.reltablespace AS spcoid,rel.relacl AS relacl_str, (CASE WHEN length(spc.spcname::text) \u003e 0 OR rel.relkind = 'p' THEN spc.spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END) as spcname, (CASE rel.relreplident WHEN 'd' THEN 'default' WHEN 'n' THEN 'nothing' WHEN 'f' THEN 'full' WHEN 'i' THEN 'index' END) as replica_identity, (select nspname FROM pg_catalog.pg_namespace WHERE oid = 2200::oid ) as schema, pg_catalog.pg_get_userbyid(rel.relowner) AS relowner, rel.relkind, (CASE WHEN rel.relkind = 'p' THEN true ELSE false END) AS is_partitioned, rel.relhassubclass, rel.reltuples::bigint, des.description, con.conname, con.conkey, EXISTS(select 1 FROM pg_catalog.pg_trigger JOIN pg_catalog.pg_proc pt ON pt.oid=tgfoid AND pt.proname='logtrigger' JOIN pg_catalog.pg_proc pc ON pc.pronamespace=pt.pronamespace AND pc.proname='slonyversion' WHERE tgrelid=rel.oid) AS isrepl, (SELECT count(*) FROM pg_catalog.pg_trigger WHERE tgrelid=rel.oid AND tgisinternal = FALSE) AS triggercount, (SELECT ARRAY(SELECT CASE WHEN (nspname NOT LIKE 'pg\\_%') THEN pg_catalog.quote_ident(nspname)||'.'||pg_catalog.quote_ident(c.relname) ELSE pg_catalog.quote_ident(c.relname) END AS inherited_tables FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid ORDER BY inhseqno)) AS coll_inherits, (SELECT count(*) FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid) AS inherited_tables_cnt, (CASE WHEN rel.relpersistence = 'u' THEN true ELSE false END) AS relpersistence, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'fillfactor=([0-9]*)') AS fillfactor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'parallel_workers=([0-9]*)') AS parallel_workers, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'toast_tuple_target=([0-9]*)') AS toast_tuple_target, (substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS autovacuum_enabled, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS autovacuum_freeze_table_age, (substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS toast_autovacuum_enabled, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS toast_autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS toast_autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS toast_autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS toast_autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS toast_autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS toast_autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS toast_autovacuum_freeze_table_age, rel.reloptions AS reloptions, tst.reloptions AS toast_reloptions, rel.reloftype, CASE WHEN typ.typname IS NOT NULL THEN (select pg_catalog.quote_ident(nspname) FROM pg_catalog.pg_namespace WHERE oid = 2200::oid )||'.'||pg_catalog.quote_ident(typ.typname) ELSE typ.typname END AS typname, typ.typrelid AS typoid, rel.relrowsecurity as rlspolicy, rel.relforcerowsecurity as forcerlspolicy, (CASE WHEN rel.reltoastrelid = 0 THEN false ELSE true END) AS hastoasttable, (SELECT pg_catalog.array_agg(provider || '=' || label) FROM pg_catalog.pg_seclabels sl1 WHERE sl1.objoid=rel.oid AND sl1.objsubid=0) AS seclabels, (CASE WHEN rel.oid \u003c= 13756::oid THEN true ElSE false END) AS is_sys_table -- Added for partition table , (CASE WHEN rel.relkind = 'p' THEN pg_catalog.pg_get_partkeydef(16396::oid) ELSE '' END) AS partition_scheme FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=rel.oid AND des.objsubid=0 AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND NOT rel.relispartition AND rel.oid = 16396::oid ORDER BY rel.relname; https://github.com/postgres/pgadmin4\n","description":"","tags":null,"title":"Get_postgres_create_table_sql","uri":"/posts/get_postgres_create_table_sql/"},{"categories":null,"content":"EventBus 的使用及注意点 使用 创建全局实例 1 static final EventBus INSTANCE = new EventBus(); 将含有 @Subscribe 的方法注册到全局实例上 1 INSTANCE.register(this); 发送 event 1 INSTANCE.post(event); 流程分析 采用上述方式时有以下几个注意点\n发送事件并且接受后处理事件是同步执行的，即同一个线程执行 如果在接受事件方法中有嵌套发送事件，那么该嵌套发送的事件不会立即执行，会等到第一个事件的接收方法完成后，再执行第二个事件。 EventBus 调用流程分析 创建 EventBus 实例 将订阅者注册到 EventBus 实例上 创建 EventBus 实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public EventBus() { this(\"default\"); } /** * Creates a new EventBus with the given {@code identifier}. * * @param identifier a brief name for this bus, for logging purposes. Should be a valid Java * identifier. */ public EventBus(String identifier) { this( identifier, // 同步执行器 MoreExecutors.directExecutor(), Dispatcher.perThreadDispatchQueue(), LoggingHandler.INSTANCE); } 1 2 3 4 5 6 7 8 9 10 11 12 private static final class PerThreadQueuedDispatcher extends Dispatcher { // This dispatcher matches the original dispatch behavior of EventBus. /** Per-thread queue of events to dispatch. */ private final ThreadLocal\u003cQueue\u003cEvent\u003e\u003e queue = new ThreadLocal\u003cQueue\u003cEvent\u003e\u003e() { @Override protected Queue\u003cEvent\u003e initialValue() { return Queues.newArrayDeque(); } }; 注册 EventBus 订阅者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 /** * Registers all subscriber methods on {@code object} to receive events. * * @param object object whose subscriber methods should be registered. */ public void register(Object object) { subscribers.register(object); } /** Registers all subscriber methods on the given listener object. */ void register(Object listener) { Multimap\u003cClass\u003c?\u003e, Subscriber\u003e listenerMethods = findAllSubscribers(listener); for (Entry\u003cClass\u003c?\u003e, Collection\u003cSubscriber\u003e\u003e entry : listenerMethods.asMap().entrySet()) { Class\u003c?\u003e eventType = entry.getKey(); Collection\u003cSubscriber\u003e eventMethodsInListener = entry.getValue(); CopyOnWriteArraySet\u003cSubscriber\u003e eventSubscribers = subscribers.get(eventType); if (eventSubscribers == null) { CopyOnWriteArraySet\u003cSubscriber\u003e newSet = new CopyOnWriteArraySet\u003c\u003e(); eventSubscribers = MoreObjects.firstNonNull(subscribers.putIfAbsent(eventType, newSet), newSet); } eventSubscribers.addAll(eventMethodsInListener); } } /** * Returns all subscribers for the given listener grouped by the type of event they subscribe to. */ private Multimap\u003cClass\u003c?\u003e, Subscriber\u003e findAllSubscribers(Object listener) { Multimap\u003cClass\u003c?\u003e, Subscriber\u003e methodsInListener = HashMultimap.create(); Class\u003c?\u003e clazz = listener.getClass(); for (Method method : getAnnotatedMethods(clazz)) { Class\u003c?\u003e[] parameterTypes = method.getParameterTypes(); Class\u003c?\u003e eventType = parameterTypes[0]; methodsInListener.put(eventType, Subscriber.create(bus, listener, method)); } return methodsInListener; } /** Creates a {@code Subscriber} for {@code method} on {@code listener}. */ static Subscriber create(EventBus bus, Object listener, Method method) { return isDeclaredThreadSafe(method) ? new Subscriber(bus, listener, method) // 调用方法采用 synchronized : new SynchronizedSubscriber(bus, listener, method); } 发送 event 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 /** * Posts an event to all registered subscribers. This method will return successfully after the * event has been posted to all subscribers, and regardless of any exceptions thrown by * subscribers. * * \u003cp\u003eIf no subscribers have been subscribed for {@code event}'s class, and {@code event} is not * already a {@link DeadEvent}, it will be wrapped in a DeadEvent and reposted. * * @param event event to post. */ public void post(Object event) { Iterator\u003cSubscriber\u003e eventSubscribers = subscribers.getSubscribers(event); if (eventSubscribers.hasNext()) { dispatcher.dispatch(event, eventSubscribers); } else if (!(event instanceof DeadEvent)) { // the event had no subscribers and was not itself a DeadEvent post(new DeadEvent(this, event)); } } // 这里需要注意，如果当前线程在调用的 post 方法中，嵌套调用 post，第二个 post方法不会立刻执行，而是会加入 队列中，等到队列中第一个任务处理完，才会继续处理。 @Override void dispatch(Object event, Iterator\u003cSubscriber\u003e subscribers) { checkNotNull(event); checkNotNull(subscribers); Queue\u003cEvent\u003e queueForThread = queue.get(); queueForThread.offer(new Event(event, subscribers)); if (!dispatching.get()) { dispatching.set(true); try { Event nextEvent; while ((nextEvent = queueForThread.poll()) != null) { while (nextEvent.subscribers.hasNext()) { nextEvent.subscribers.next().dispatchEvent(nextEvent.event); } } } finally { dispatching.remove(); queue.remove(); } } } ","description":"","tags":null,"title":"guava EventBus 使用以及注意点","uri":"/posts/second/"},{"categories":null,"content":"背景 Apache ShardingSphere 基于用户的实际使用场景，为用户打造了多种实用功能，包括数据分片、读写分离等。在数据分片功能中，Apache ShardingSphere 提供了标准分片、复合分片等多种实用的分片策略，在各种分片策略中，用户又可以配置相关分片算法，从而解决数据分片的问题。在读写分离功能中，ShardingSphere 为用户提供了静态和动态的两种读写分离类型以及丰富的负载均衡算法以满足用户实际需求。 可以看到 ShardingSphere 的分片和读写分离功能已经非常丰富，不过用户的真实使用场景是千变万化的。以多租户场景为例，用户期望按照登录账号所属租户进行分片，但是租户信息却并不是存在于每条业务 SQL 中，这时从 SQL 中提取分片字段的算法将无法发挥作用。再以读写分离为例，大部分场景下用户都希望能够将查询操作路由到从库上执行，但是在某些实时性要求很高的场景下，用户希望将 SQL 强制路由到主库执行，这时读写分离就无法满足业务要求。 基于以上痛点 Apache ShardingSphere 为用户提供了 Hint 功能，用户可以结合实际业务场景，利用 SQL 外部的逻辑进行强制路由或者分片。目前 ShardingSphere 为用户提供了两种 Hint 方式，一种通过 Java API 手动编程，利用 HintManager 进行强制路由和分片，这种方式对采用 JDBC 编程的应用非常友好，只需要少量的代码编写，就能够轻松实现不依赖 SQL 的分片或者强制路由功能。另外一种方式对于不懂开发的 DBA 而言更加友好，ShardingSphere 基于分布式 SQL 提供的使用方式，利用 SQL HINT 和 DistSQL HINT， 为用户提供了无需编码就能实现的分片和强制路由功能。接下来，让我们一起了解下这两种使用方式。\n基于 HintManager 的手动编程 ShardingSphere 主要通过 HintManager 对象来实现强制路由和分片的功能。利用 HintManager，用户的分片将不用再依赖 SQL。它可以极大地扩展用户的使用场景，让用户可以更加灵活地进行数据分片或者强制路由。目前通过 HintManager，用户可以配合 ShardingSphere 内置的或者自定义的 Hint 算法实现分片功能，还可以通过设置指定数据源或者强制主库读写，实现强制路由功能。在学习 HintManager 的使用之前，让我们先来简单地了解一下它的实现原理，这有助于我们更好地使用它。\nHintManager 实现原理 其实通过查看 HintManager 代码，我们可以快速地了解它的原理。\n1 2 3 4 5 @NoArgsConstructor(access = AccessLevel.PRIVATE) public final class HintManager implements AutoCloseable { private static final ThreadLocal\u003cHintManager\u003e HINT_MANAGER_HOLDER = new ThreadLocal\u003c\u003e(); } 正如你所看到的，ShardingSphere 通过 ThreadLocal 来实现 HintManager 的功能，只要在同一个线程中，用户的分片设置都会得以保留。因此，只要用户在执行 SQL 之前调用 HintManager 相关功能，ShardingSphere 就能在当前线程中获取用户设置的分片或强制路由条件，从而进行分片或者路由操作。了解了 HintManager 的原理之后，让我们一起来学习一下它的使用。\nHintManager 的使用 使用 Hint 分片 Hint 分片算法需要用户实现 org.apache.shardingsphere.sharding.api.sharding.hint.HintShardingAlgorithm 接口。 Apache ShardingSphere 在进行路由时，将会从 HintManager 中获取分片值进行路由操作。\n参考配置如下： rules: - !SHARDING tables: t_order: actualDataNodes: demo_ds_${0..1}.t_order_${0..1} databaseStrategy: hint: algorithmClassName: xxx.xxx.xxx.HintXXXAlgorithm tableStrategy: hint: algorithmClassName: xxx.xxx.xxx.HintXXXAlgorithm defaultTableStrategy: none: defaultKeyGenerateStrategy: type: SNOWFLAKE column: order_id props: sql-show: true 获取 HintManager 实例 HintManager hintManager = HintManager.getInstance();\n添加分片键 使用 hintManager.addDatabaseShardingValue 来添加数据源分片键值。 使用 hintManager.addTableShardingValue 来添加表分片键值。 分库不分表情况下，强制路由至某一个分库时，可使用 hintManager.setDatabaseShardingValue 方式添加分片。 清除分片键值 分片键值保存在 ThreadLocal 中，所以需要在操作结束时调用 hintManager.close() 来清除 ThreadLocal 中的内容。 完整代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.addDatabaseShardingValue(\"t_order\", 1); hintManager.addTableShardingValue(\"t_order\", 2); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.setDatabaseShardingValue(3); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } 使用 Hint 强制主库路由 获取 HintManager 与基于 Hint 的数据分片相同。\n设置主库路由 使用 hintManager.setWriteRouteOnly 设置主库路由。 清除分片键值 与基于 Hint 的数据分片相同。\n完整代码示例 1 2 3 4 5 6 7 8 9 10 11 String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.setWriteRouteOnly(); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } 使用 Hint 路由至指定数据库 获取 HintManager 与基于 Hint 的数据分片相同。\n设置路由至指定数据库 使用 hintManager.setDataSourceName 设置数据库名称。 完整代码示例 1 2 3 4 5 6 7 8 9 10 11 String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.setDataSourceName(\"ds_0\"); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } 清除强制路由值 与基于 Hint 的数据分片相同。\n在了解了基于 HintManager 的手动编程方式之后，让我们一起来了解 ShardingSphere 基于分布式 SQL 提供的另一种 Hint 的解决方案。\n基于分布式 SQL 的 Hint Apache ShardingSphere 的分布式 SQL HINT 主要由两种功能组成，一种叫做 SQL HINT，即基于 SQL 注释的方式提供的功能，另外一种是通过 DistSQL 实现的作用于 HintManager 的功能。\nSQL HINT SQL HINT 就是通过在 SQL 语句上增加注释，从而实现强制路由的一种 Hint 方式。它降低了用户改造代码的成本，同时完全脱离了 Java API 的限制，不仅可以在 ShardingSphere-JDBC 中使用，也可以直接在 ShardingSphere-Proxy 上使用。 以下面 SQL 为例，即使用户配置了针对 t_order 的相关分片算法，该 SQL 也会直接在数据库 ds_0 上原封不动地执行，并返回执行结果。\n1 2 /* ShardingSphere hint: dataSourceName=ds_0 */ SELECT * FROM t_order; 通过注释的方式我们可以方便地将 SQL 直接送达指定数据库执行而无视其它分片逻辑。以多租户场景为例，用户不用再配置复杂的分库逻辑，也无需改造业务逻辑，只需要将指定库添加到注释信息中即可。在了解了 SQL HINT 的基本使用之后，让我们一起来了解一下 SQL HINT 的实现原理。\nSQL HINT 的实现原理 其实了解 Apache ShardingSphere 的读者朋友们一定对 SQL 解析引擎不会感到陌生。SQL HINT 实现的第一步就是提取 SQL 中的注释信息。利用 antlr4 的通道功能，可以将 SQL 中的注释信息单独送至特定的隐藏通道，ShardingSphere 也正是利用该功能，在生成解析结果的同时，将隐藏通道中的注释信息一并提取出来了。具体实现如下方代码所示。\n将 SQL 中的注释送入隐藏通道。 lexer grammar Comments; import Symbol; BLOCK_COMMENT: '/*' .*? '*/' -\u003e channel(HIDDEN); INLINE_COMMENT: (('-- ' | '#') ~[\\r\\n]* ('\\r'? '\\n' | EOF) | '--' ('\\r'? '\\n' | EOF)) -\u003e channel(HIDDEN); 访问语法树后增加对于注释信息的提取： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public \u003cT\u003e T visit(final ParseContext parseContext) { ParseTreeVisitor\u003cT\u003e visitor = SQLVisitorFactory.newInstance(databaseType, visitorType, SQLVisitorRule.valueOf(parseContext.getParseTree().getClass()), props); T result = parseContext.getParseTree().accept(visitor); appendSQLComments(parseContext, result); return result; } private \u003cT\u003e void appendSQLComments(final ParseContext parseContext, final T visitResult) { if (!parseContext.getHiddenTokens().isEmpty() \u0026\u0026 visitResult instanceof AbstractSQLStatement) { Collection\u003cCommentSegment\u003e commentSegments = parseContext.getHiddenTokens().stream().map(each -\u003e new CommentSegment(each.getText(), each.getStartIndex(), each.getStopIndex())) .collect(Collectors.toList()); ((AbstractSQLStatement) visitResult).getCommentSegments().addAll(commentSegments); } } 提取出用户 SQL 中的注释信息之后，我们就需要根据注释信息来进行相关强制路由了。既然是路由，那么自然就需要使用 Apache ShardingSphere 的路由引擎，我们在路由引擎上做了一些针对 HINT 的改造。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public RouteContext route(final LogicSQL logicSQL, final ShardingSphereMetaData metaData) { RouteContext result = new RouteContext(); Optional\u003cString\u003e dataSourceName = findDataSourceByHint(logicSQL.getSqlStatementContext(), metaData.getResource().getDataSources()); if (dataSourceName.isPresent()) { result.getRouteUnits().add(new RouteUnit(new RouteMapper(dataSourceName.get(), dataSourceName.get()), Collections.emptyList())); return result; } for (Entry\u003cShardingSphereRule, SQLRouter\u003e entry : routers.entrySet()) { if (result.getRouteUnits().isEmpty()) { result = entry.getValue().createRouteContext(logicSQL, metaData, entry.getKey(), props); } else { entry.getValue().decorateRouteContext(result, logicSQL, metaData, entry.getKey(), props); } } if (result.getRouteUnits().isEmpty() \u0026\u0026 1 == metaData.getResource().getDataSources().size()) { String singleDataSourceName = metaData.getResource().getDataSources().keySet().iterator().next(); result.getRouteUnits().add(new RouteUnit(new RouteMapper(singleDataSourceName, singleDataSourceName), Collections.emptyList())); } return result; } ShardingSphere 首先发现了符合定义的 SQL 注释，再经过基本的校验之后，就会直接返回用户指定的路由结果，从而实现强制路由功能。在了解了 SQL HINT 的基本原理之后，让我们一起学习如何使用 SQL HINT。\n如何使用 SQL HINT SQL HINT 的使用非常简单，无论是 ShardingSphere-JDBC 还是 ShardingSphere-Porxy，都可以使用。 第一步打开注释解析开关。将 sqlCommentParseEnabled 设置为 true。 第二步在 SQL 上增加注释即可。目前 SQL HINT 支持指定数据源路由和主库路由。\n指定数据源路由：目前只支持路由至一个数据源。 注释格式暂时只支持/* /，内容需要以ShardingSphere hint:开始，属性名为 dataSourceName。 / ShardingSphere hint: dataSourceName=ds_0 */ SELECT * FROM t_order;\n主库路由：注释格式暂时只支持/* /，内容需要以ShardingSphere hint:开始，属性名为 writeRouteOnly。 / ShardingSphere hint: writeRouteOnly=true */ SELECT * FROM t_order;\nDistSQL HINT Apache ShardingSphere 的 DistSQL 也提供了 Hint 相关功能，让用户可以通过 ShardingSphere-Proxy 来实现分片和强制路由功能。\nDistSQL HINT 的实现原理 同前文一致，在学习使用 DistSQL HINT 功能之前，让我们一起来了解一下 DistSQL Hint 的实现原理。DistSQL HINT 的实现原理非常简单，其实就是通过操作 HintManager 实现的 HINT 功能。以读写分离 Hint 为例，当用户通过 ShardingSphere-Proxy 执行以下 SQL 时，其实 ShardingSphere 内部对 SQL 做了如下方代码所示的操作。 – 强制主库读写\n1 set readwrite_splitting hint source = write 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @RequiredArgsConstructor public final class SetReadwriteSplittingHintExecutor extends AbstractHintUpdateExecutor\u003cSetReadwriteSplittingHintStatement\u003e { private final SetReadwriteSplittingHintStatement sqlStatement; @Override public ResponseHeader execute() { HintSourceType sourceType = HintSourceType.typeOf(sqlStatement.getSource()); switch (sourceType) { case AUTO: HintManagerHolder.get().setReadwriteSplittingAuto(); break; case WRITE: HintManagerHolder.get().setWriteRouteOnly(); break; default: break; } return new UpdateResponseHeader(new EmptyStatement()); } } @NoArgsConstructor(access = AccessLevel.PRIVATE) public final class HintManagerHolder { private static final ThreadLocal\u003cHintManager\u003e HINT_MANAGER_HOLDER = new ThreadLocal\u003c\u003e(); /** * Get an instance for {@code HintManager} from {@code ThreadLocal},if not exist,then create new one. * * @return hint manager */ public static HintManager get() { if (HINT_MANAGER_HOLDER.get() == null) { HINT_MANAGER_HOLDER.set(HintManager.getInstance()); } return HINT_MANAGER_HOLDER.get(); } /** * remove {@code HintManager} from {@code ThreadLocal}. */ public static void remove() { HINT_MANAGER_HOLDER.remove(); } } 用户执行 SQL 之后，DistSQL 解析引擎会首先识别出该 SQL 是读写分离 Hint 的 SQL，同时会提取出用户想要自动路由或者强制到主库的字段。之后它会采用 SetReadwriteSplittingHintExecutor 执行器去执行 SQL，从而将正确操作设置到 HintManager 中，进而实现强制路由主库的功能。\nDistSQL HINT 的使用 下表为大家展示了 DistSQL Hint 的相关语法。\n语句 说明 示例 set readwrite_splitting hint source = [auto / write] 针对当前连接，设置读写分离的路由策略（自动路由或强制到写库） set readwrite_splitting hint source = write set sharding hint database_value = yy 针对当前连接，设置 hint 仅对数据库分片有效，并添加分片值，yy：数据库分片值 set sharding hint database_value = 100 add sharding hint database_value xx = yy 针对当前连接，为表 xx 添加分片值 yy，xx：逻辑表名称，yy：数据库分片值 add sharding hint database_value t_order= 100 add sharding hint table_value xx = yy 针对当前连接，为表 xx 添加分片值 yy，xx：逻辑表名称，yy：表分片值 add sharding hint table_value t_order = 100 clear hint 针对当前连接，清除 hint 所有设置 clear hint clear [sharding hint / readwrite_splitting hint] 针对当前连接，清除 sharding 或 readwrite_splitting 的 hint 设置 clear readwrite_splitting hint show [sharding / readwrite_splitting] hint status 针对当前连接，查询 sharding 或 readwrite_splitting 的 hint 设置 show readwrite_splitting hint status 本文详细介绍了 Hint 使用的两种方式以及基本原理，相信通过本文，读者朋友们对 Hint 都有了一些基本了解了，大家可以根据自己的需求来选择使用合适的方式。如果在使用过程中遇到任何问题，或者有任何建议想法，都欢迎来社区反馈。\n","description":"","tags":null,"title":"ShardingSphere Hint 实用指南","uri":"/posts/my-first-post/"}]
