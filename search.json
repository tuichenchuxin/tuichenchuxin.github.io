[{"categories":null,"content":"TiDB 使用 创建表时可以设置数据过期时间，然后后台定时任务删除相关数据\n产品文档：https://docs.pingcap.com/zh/tidb/dev/time-to-live\n功能列表 功能 备注 create 语句中增加 TTL 属性，指定表中数据的过期时间 create 语句中增加注释信息(兼容 MySQL)，包含 TTL 属性 alter 语句修改 TTL 属性 TTL 可以配合表中其它列的属性来使用 可以指定 TTL 任务时间间隔 PolarDB-X 创建 TTL 表，按照时间分区，定期删除和创建相关分区表\n产品文档： https://help.aliyun.com/document_detail/403528.html\n功能列表 功能 备注 对按照时间进行 range 分区的表，定时失效过期分区，定时提前创建分区 仅用在自动模式下的分区表上 支持通过 DDL 语句来定义相关分区的 TTL TTL表支持的时间分区列类型为：date、datetime； 所有的唯一键（包括主键）必须包含TTL表的local partition by range时间分区列；所有的唯一键（包括主键）必须包含TTL表的local partition by range时间分区列 支持查看分区信息以及过期时间等 information_schema.local_partitions 支持校验物理表的物理分区的完整性 支持 Alter 语句手动创建新分区表/删除过期分区表 支持普通表和 TTL 表互相转换 支持创建、查看、删除 TTL 定时任务 Google Spanner 创建表时可以设置行删除策略，后台任务扫描表并删除相关行\n产品文档：https://cloud.google.com/spanner/docs/ttl?hl=zh-cn\n功能列表 功能 备注 create 语句中增加行删除策略 alter 语句修改行删除策略 查看表的 TTL 删除情况 ","description":"","tags":null,"title":"DataTTL 相关调研","uri":"/posts/datattl/"},{"categories":null,"content":"目标 新增 SS 默认系统库，初步支持全局静态元数据（编码、事务隔离级别）管理 设计元数据调度收集功能，支持 ShardingSphere 动态元数据管理（数据分布等信息） 现状 当前 ss 缺乏自己的元数据信息，例如分片的数据分布、编码等等。\n之前为了解决各个客户端连接报错的问题，设计了各个数据库方言的模拟库。 只有用户表会从真实数据库获取，其他表都是通过 yaml 文件来模拟存储到 zk 的。\n元数据存储调研 MySQL Mysql 将相关参数放在 variables_info 并将相关值设置在全局或 session 级别对应的表中\n1 2 3 4 5 6 7 8 9 10 11 mysql\u003e show tables like '%variables%'; +--------------------------------------------+ | Tables_in_performance_schema (%variables%) | +--------------------------------------------+ | global_variables | | persisted_variables | | session_variables | | user_variables_by_thread | | variables_by_thread | | variables_info | +--------------------------------------------+ 查询隔离级别\n1 2 3 4 5 6 7 8 9 10 11 mysql\u003e SELECT VI.VARIABLE_NAME, GV.VARIABLE_VALUE, VI.MIN_VALUE, VI.MAX_VALUE FROM performance_schema.variables_info AS VI INNER JOIN performance_schema.global_variables AS GV USING (VARIABLE_NAME) where variable_name = 'transaction_isolation' ORDER BY VARIABLE_NAME; +-----------------------+-----------------+-----------+-----------+ | VARIABLE_NAME | VARIABLE_VALUE | MIN_VALUE | MAX_VALUE | +-----------------------+-----------------+-----------+-----------+ | transaction_isolation | REPEATABLE-READ | 0 | 0 | +-----------------------+-----------------+-----------+-----------+ 1 row in set (0.01 sec) Postgres pg_settings 表\n1 2 3 4 5 postgres=# select * from pg_settings where name = 'default_transaction_isolation'; name | setting | unit | category | short_desc | extra_desc | context | vartype | source | min_val | max_val | enumvals | boot_val | reset_val | sourcefile | sourceline | pending_restart -------------------------------+----------------+------+-------------------------------------------------+---------------------------------------------------------------+------------+---------+---------+---------+---------+---------+----------------------------------------------------------------------+----------------+----------------+------------+------------+----------------- default_transaction_isolation | read committed | | Client Connection Defaults / Statement Behavior | Sets the transaction isolation level of each new transaction. | | user | enum | default | | | {serializable,\"repeatable read\",\"read committed\",\"read uncommitted\"} | read committed | read committed | | | f (1 row) PolarDB-X Polardb-x 的元数据库 Polardb-x 中维护了自己的元数据库用于内部流程的使用 它的元数据中几乎维护了所有需要的信息，例如 tables，columns，lock，ddl_job, schedule job 等。 另外在内存中也维护了一份元数据信息，主要是表、列。内存中元数据来源于存储在 mysql 中的元数据，每次 ddl 执行后，都会生成刷新对应表的任务，通过任务触发 cn 从 mysql 中查询并缓存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 mysql\u003e show tables; +---------------------------------------+ | Tables_in_polardbx_meta_db_polardbx | +---------------------------------------+ | __test_sequence | | __test_sequence_opt | | audit_log | | backfill_objects | | baseline_info | | binlog_polarx_command | | character_sets | | checker_reports | | collation_character_set_applicability | | collations | | column_metas | | column_statistics | | columns | | complex_task_outline | | concurrency_control_rule | | concurrency_control_trigger | | config_listener | | db_group_info | | db_info | | db_priv | | ddl_engine | | ddl_engine_archive | | ddl_engine_task | | ddl_engine_task_archive | | ddl_plan | | default_role_state | | engines | | feature_usage_statistics | | file_storage_files_meta | | file_storage_info | | files | | fired_scheduled_jobs | | global_variables | | group_detail_info | | indexes | | inst_config | | inst_lock | | key_column_usage | | locality_info | | node_info | | partition_group | | partition_group_delta | | partitions | | plan_info | | quarantine_config | | read_write_lock | | recycle_bin | | referential_constraints | | role_priv | | scaleout_backfill_objects | | scaleout_checker_reports | | scaleout_outline | | scheduled_jobs | | schema_change | | schemata | | sequence | | sequence_opt | | server_info | | session_variables | | storage_info | | table_constraints | | table_group | | table_local_partitions | | table_partitions | | table_partitions_delta | | table_priv | | table_statistics | | tablegroup_outline | | tables | | tables_ext | | user_login_error_limit | | user_priv | | variable_config | | views | +---------------------------------------+ 74 rows in set (0.02 sec) 从DDL的执行来看 polardb-x 的元数据使用 简述：整个 ddl 过程中涉及了 ddl-job 任务相关表的使用（ddl_engine 、ddl_engine_task ）,表相关元数据的使用（tables、tables_ext、columns）以及锁 （read_write_lock）等。 以 DDL 语句为例，我们看一下 polardb-x 是怎么使用 metadata 的\n1 CREATE TABLE t1(id bigint not null auto_increment, name varchar(30), primary key(id)) dbpartition by hash(id); SQL语句进入PolarDB-X的CN后，将经历协议层、优化器、执行器的完整处理流程。首先经过解析、鉴权、校验，被解析为关系代数树后，在优化器中经历RBO和CBO生成执行计划，最终在DN上执行完成。 由于 DDL 涉及元数据的变更，所以可能会造成系统状态的不一致。所以 polardb-x 通过 ddl job 配合 metadataDb 以及 双版本元数据 + MDL锁来解决这个问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Override public Cursor handle(RelNode logicalPlan, ExecutionContext executionContext) { BaseDdlOperation logicalDdlPlan = (BaseDdlOperation) logicalPlan; initDdlContext(logicalDdlPlan, executionContext); // Validate the plan first and then return immediately if needed. boolean returnImmediately = validatePlan(logicalDdlPlan, executionContext); boolean isNewPartDb = DbInfoManager.getInstance().isNewPartitionDb(logicalDdlPlan.getSchemaName()); if (isNewPartDb) { setPartitionDbIndexAndPhyTable(logicalDdlPlan); } else { setDbIndexAndPhyTable(logicalDdlPlan); } // Build a specific DDL job by subclass. DdlJob ddlJob = returnImmediately? new TransientDdlJob(): buildDdlJob(logicalDdlPlan, executionContext); // Validate the DDL job before request. validateJob(logicalDdlPlan, ddlJob, executionContext); // Handle the client DDL request on the worker side. handleDdlRequest(ddlJob, executionContext); if (executionContext.getDdlContext().isSubJob()){ return buildSubJobResultCursor(ddlJob, executionContext); } return buildResultCursor(logicalDdlPlan, executionContext); } 将 sql 转化为执行计划后，就会创建 ddl job, ddl job 中包含了新增表信息到元数据库、创建物理表、同步元数据信息等任务。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Override protected ExecutableDdlJob doCreate() { CreateTableValidateTask validateTask = new CreateTableValidateTask(schemaName, logicalTableName, physicalPlanData.getTablesExtRecord()); CreateTableAddTablesExtMetaTask addExtMetaTask = new CreateTableAddTablesExtMetaTask(schemaName, logicalTableName, physicalPlanData.isTemporary(), physicalPlanData.getTablesExtRecord(), autoPartition); CreateTablePhyDdlTask phyDdlTask = new CreateTablePhyDdlTask(schemaName, logicalTableName, physicalPlanData); CdcDdlMarkTask cdcDdlMarkTask = new CdcDdlMarkTask(schemaName, physicalPlanData); CreateTableAddTablesMetaTask addTableMetaTask = new CreateTableAddTablesMetaTask(schemaName, logicalTableName, physicalPlanData.getDefaultDbIndex(), physicalPlanData.getDefaultPhyTableName(), physicalPlanData.getSequence(), physicalPlanData.getTablesExtRecord(), physicalPlanData.isPartitioned(), physicalPlanData.isIfNotExists(), physicalPlanData.getKind(), hasTimestampColumnDefault, binaryColumnDefaultValues); LocalityDesc locality = physicalPlanData.getLocalityDesc(); StoreTableLocalityTask storeLocalityTask = locality == null ? null : new StoreTableLocalityTask(schemaName, logicalTableName, locality.toString(), false); CreateTableShowTableMetaTask showTableMetaTask = new CreateTableShowTableMetaTask(schemaName, logicalTableName); TableSyncTask tableSyncTask = new TableSyncTask(schemaName, logicalTableName); ExecutableDdlJob4CreateTable result = new ExecutableDdlJob4CreateTable(); ... result.setCreateTableValidateTask(validateTask); result.setCreateTableAddTablesExtMetaTask(addExtMetaTask); result.setCreateTablePhyDdlTask(phyDdlTask); result.setCreateTableAddTablesMetaTask(addTableMetaTask); result.setCdcDdlMarkTask(cdcDdlMarkTask); result.setCreateTableShowTableMetaTask(showTableMetaTask); result.setTableSyncTask(tableSyncTask); return result; 创建 ddl job 之后，就会下发执行任务，storeJob 会将相关 job 写入ddl_engine_task,ddl_engine 表中。 notifyLeader 会通知相关 cn 节点执行 ddl job。ddl job 会更新元数据库中的 tables columns 等表，如果有多个 cn 节点，这里会触发节点间同步，收到同步信息的节点会从元数据中获取相关信息，并更新 cn 内缓存的元数据信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void execute() { ddlContext.setResources(ddlJob.getExcludeResources()); // Create a new job and put it in the queue. ddlJobManager.storeJob(ddlJob, ddlContext); // Request the leader to perform the job. DdlRequest ddlRequest = notifyLeader(ddlContext.getSchemaName(), Lists.newArrayList(ddlContext.getJobId())); // Wait for response from the leader, then respond to the client. if (ddlContext.isAsyncMode()) { return; } respond(ddlRequest, ddlJobManager, executionContext, true); } 关于元数据 GMS 三副本节点 polarDb-x 的元数据存储于内置的 GMS 三副本节点中，提供了全局时间戳来提供外部一致性读，具体可以参考：PolarDB-X 全局时间戳服务的设计 PolarDB-X 一致性共识协议 (X-Paxos)-阿里云开发者社区\nCockroachDB Cockroach db 的内置元数据库 Cockroach 的底层存储结构如下： 内置元数据设计 方案：表结构和存储分开，yaml 模拟表结构 流程图 Zk 结构 以 分片表数据量统计表 为例\ncreate table sharding_table_statistics ( id int, logic_database_name varchar(100), logic_table_name varchar(100), actual_database_name varchar(100), actual_table_name varchar(100), row_count BIGINT, size BIGINT ) 对应 zk 存储结构 红色为修改，黄色为新增，蓝色为 PG 特有（pg 同一个实例上的库是不共享元数据信息的，所以 pg 的 shardingsphere schema 增加在用户创建的逻辑库下，当然 postgres 库下也会模拟一个 shardingsphere schema）\n初始化\n通过 yaml 模拟生成表结构（同现有 information_schema 流程） 从 zk 获取 ShardingSphereData 对象 如果未获取到，根据表结构初始化 ShardingSphereData 对象 注册表结构到 calcite 方便进行查询使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public static MetaDataContexts create(final MetaDataPersistService persistService, final ContextManagerBuilderParameter parameter, final InstanceContext instanceContext) throws SQLException { Collection\u003cString\u003e databaseNames = instanceContext.getInstance().getMetaData() instanceof JDBCInstanceMetaData ? parameter.getDatabaseConfigs().keySet() : persistService.getDatabaseMetaDataService().loadAllDatabaseNames(); Map\u003cString, DatabaseConfiguration\u003e effectiveDatabaseConfigs = createEffectiveDatabaseConfigurations(databaseNames, parameter.getDatabaseConfigs(), persistService); Collection\u003cRuleConfiguration\u003e globalRuleConfigs = persistService.getGlobalRuleService().load(); ConfigurationProperties props = new ConfigurationProperties(persistService.getPropsService().load()); // 增加元数据库表结构的初始化 Map\u003cString, ShardingSphereDatabase\u003e databases = ShardingSphereDatabasesFactory.create(effectiveDatabaseConfigs, props, instanceContext); databases.putAll(reloadDatabases(databases, persistService)); ShardingSphereRuleMetaData globalMetaData = new ShardingSphereRuleMetaData(GlobalRulesBuilder.buildRules(globalRuleConfigs, databases, instanceContext, props)); ShardingSphereMetaData metaData = new ShardingSphereMetaData(databases, globalMetaData, props); ShardingSphereData shardingSphereData = initShardingSphereData(persistService, metaData, instanceContext); return new MetaDataContexts(persistService, metaData, shardingSphereData); } 1 2 3 4 5 6 7 private static ShardingSphereData initShardingSphereData(final MetaDataPersistService persistService, final ShardingSphereMetaData metaData, final InstanceContext instanceContext) { // 先从 zk 加载，没有的话就依赖之前的表结构进行初始化 ShardingSphereData result = persistService.getShardingSphereDataPersistService().load().orElse(ShardingSphereDataFactory.getInstance(metaData)); // 注册表结构到 calcite 方便后续查询使用 result.registerShardingSphereDataQueryEngine(metaData, instanceContext.getEventBusContext()); return result; } 初始化数据收集任务 （目前考虑采用监听 zk 的方式来触发相关任务的收集 + 定时任务收集） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Slf4j public final class ShardingSphereDataContextManagerLifecycleListener implements ContextManagerLifecycleListener { @Override public void onInitialized(final ModeConfiguration modeConfig, final ContextManager contextManager) { ShardingSphereDataJobWorker.initialize(contextManager); } } public final class ShardingSphereDataJobWorker { private static final AtomicBoolean WORKER_INITIALIZED = new AtomicBoolean(false); /** * Initialize job worker. * @param contextManager context manager */ public static void initialize(final ContextManager contextManager) { if (WORKER_INITIALIZED.get()) { return; } synchronized (WORKER_INITIALIZED) { if (WORKER_INITIALIZED.get()) { return; } log.info(\"start worker initialization\"); // 开启定时收集线程 startScheduleThread(contextManager); // 监听 收集任务 zk 节点 ShardingSphereDataNodeWatcher.getInstance(); WORKER_INITIALIZED.set(true); log.info(\"worker initialization done\"); } } private static void startScheduleThread(final ContextManager contextManager) { // TODO start thread to collect data } } 内存中数据结构如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public final class MetaDataContexts implements AutoCloseable { private final MetaDataPersistService persistService; private final ShardingSphereMetaData metaData; private final ShardingSphereData shardingSphereData; /** * Sharding sphere data. */ @Getter public final class ShardingSphereData { .. // key: table name value: table data private final Map\u003cString, ShardingSphereTableData\u003e tableData = new LinkedHashMap\u003c\u003e(); .. } @RequiredArgsConstructor @Getter public class ShardingSphereTableData { private final String name; private final List\u003cShardingSphereRowData\u003e rows = new LinkedList\u003c\u003e(); } @RequiredArgsConstructor @Getter public class ShardingSphereRowData { private final List\u003cObject\u003e row; } 内存中元数据的变化通过 event 发送，并同步到 zk 中，通过 zk 监听同步刷新其它节点的元数据库 元数据库的使用 利用 calcite 进行查询 增删改，通过内存对象操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Getter public final class ShardingSphereData { private final Map\u003cString, ShardingSphereTableData\u003e tableData = new LinkedHashMap\u003c\u003e(); private ShardingSphereDataQueryEngine queryEngine; /** * Query. * * @param sql sql * @return result set */ public ResultSet query(final String sql) { return queryEngine.query(sql); } /** * Register. * * @param metaData meta data * @param eventBusContext event bus */ public void registerShardingSphereDataQueryEngine(final ShardingSphereMetaData metaData, final EventBusContext eventBusContext) { ShardingSphereDataQueryEngine queryEngine = ShardingSphereDataQueryEngineFactory.getShardingSphereDataQueryEngine(); // 注册到 calcite queryEngine.init(metaData, eventBusContext, tableData); this.queryEngine = queryEngine; } } 查询的实现类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 public class ShardingSphereDataFederationQueryEngine implements ShardingSphereDataQueryEngine { private OptimizerContext optimizerContext; private ShardingSphereRuleMetaData globalRuleMetaData; private ConfigurationProperties props; private EventBusContext eventBusContext; private ShardingSphereMetaData metaData; private Map\u003cString, ShardingSphereTableData\u003e tableData; @Override public void init(final ShardingSphereMetaData metaData, final EventBusContext eventBusContext, final Map\u003cString, ShardingSphereTableData\u003e tableData) { this.optimizerContext = OptimizerContextFactory.create(metaData.getDatabases(), metaData.getGlobalRuleMetaData()); this.globalRuleMetaData = metaData.getGlobalRuleMetaData(); this.props = metaData.getProps(); this.eventBusContext = eventBusContext; this.tableData = tableData; this.metaData = metaData; } @SneakyThrows private Connection createConnection() { MemorySchema memorySchema = new MemorySchema(tableData, metaData.getDatabase(\"ShardingSphereData\").getSchema(\"ShardingSphereData\")); Properties info = new Properties(); info.setProperty(CalciteConnectionProperty.DEFAULT_NULL_COLLATION.camelName(), NullCollation.LAST.name()); info.setProperty(CalciteConnectionProperty.CASE_SENSITIVE.camelName(), \"false\"); Connection result = DriverManager.getConnection(\"jdbc:calcite:\", info); CalciteConnection calciteConnection = result.unwrap(CalciteConnection.class); SchemaPlus rootSchema = calciteConnection.getRootSchema(); rootSchema.add(\"memory\", memorySchema); return result; } @SneakyThrows @Override public ResultSet query(final String sql) { try (Connection connection = createConnection(); Statement statement = connection.createStatement()) { return statement.executeQuery(sql); } } @Override public boolean isDefault() { return true; } } Tasks use yaml to simulate ShardingSphere built in table add ShardingSphere data and persist add schedule thread or zk watch to trigger collect data support to use federation to query shardingsphere data ","description":"","tags":null,"title":"ShardingSphere 内置数据库设计","uri":"/posts/shardingspheresysdatabase/"},{"categories":null,"content":"PG \\d 支持 \\d 的现状 \\d 实际执行的语句如下\nSELECT n.nspname as \"Schema\", c.relname as \"Name\", CASE c.relkind WHEN 'r' THEN 'table' WHEN 'v' THEN 'view' WHEN 'i' THEN 'index' WHEN 'I' THEN 'global partition index' WHEN 'S' THEN 'sequence' WHEN 'L' THEN 'large sequence' WHEN 'f' THEN 'foreign table' WHEN 'm' THEN 'materialized view' WHEN 'e' THEN 'stream' WHEN 'o' THEN 'contview' END as \"Type\", pg_catalog.pg_get_userbyid(c.relowner) as \"Owner\", c.reloptions as \"Storage\" FROM pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE c.relkind IN ('r','v','m','S','L','f','e','o','') AND n.nspname \u003c\u003e 'pg_catalog' AND n.nspname \u003c\u003e 'db4ai' AND n.nspname \u003c\u003e 'information_schema' AND n.nspname !~ '^pg_toast' AND c.relname not like 'matviewmap\\_%' AND c.relname not like 'mlog\\_%' AND pg_catalog.pg_table_is_visible(c.oid) ORDER BY 1,2; 查询结果如下\nSchema | Name | Type | Owner | Storage --------+----------------------+-------+---------+---------------------------------- public | new_t_single_view | view | gaussdb | public | student10w | table | gaussdb | {orientation=row,compression=no} public | t_broadcast_table | table | gaussdb | {orientation=row,compression=no} public | t_broadcast_view_new | view | gaussdb | public | t_encrypt | table | gaussdb | {orientation=row,compression=no} public | t_order_0 | table | gaussdb | {orientation=row,compression=no} public | t_order_1 | table | gaussdb | {orientation=row,compression=no} public | t_order_view_new_0 | view | gaussdb | public | t_order_view_new_1 | view | gaussdb | public | t_single | table | gaussdb | {orientation=row,compression=no} (10 rows) 涉及的系统表有\npg_catalog.pg_class pg_catalog.pg_namespace\n涉及的函数有\npg_catalog.pg_get_userbyid(c.relowner) pg_catalog.pg_table_is_visible(c.oid)\n方案设计 方案概述 利用之前的ShardingSphere 内置数据库设计 在系统库中增加对应的表，表结构和字段类型同原生的数据库一致，并做数据收集并装饰，通过 federation 执行内存查询\n治理中心结构 表的数据收集 SELECT -- 数据库收集值 n.nspname as \"Schema\", -- 数据库收集值 c.relname as \"Name\", -- 数据库收集值 CASE c.relkind WHEN 'r' THEN 'table' WHEN 'v' THEN 'view' WHEN 'i' THEN 'index' WHEN 'I' THEN 'global partition index' WHEN 'S' THEN 'sequence' WHEN 'L' THEN 'large sequence' WHEN 'f' THEN 'foreign table' WHEN 'm' THEN 'materialized view' WHEN 'e' THEN 'stream' WHEN 'o' THEN 'contview' END as \"Type\", -- 通过 calcite 注册函数，返回 ss 中的用户信息 pg_catalog.pg_get_userbyid(c.relowner) as \"Owner\", -- 数据库收集值 c.reloptions as \"Storage\" FROM pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE c.relkind IN ('r','v','m','S','L','f','e','o','') AND n.nspname \u003c\u003e 'pg_catalog' AND n.nspname \u003c\u003e 'db4ai' AND n.nspname \u003c\u003e 'information_schema' AND n.nspname !~ '^pg_toast' AND c.relname not like 'matviewmap\\_%' AND c.relname not like 'mlog\\_%' -- 通过 calcite 注册函数，mock 返回 true AND pg_catalog.pg_table_is_visible(c.oid) ORDER BY 1,2; 需要收集 pg_class 和 pg_namespace 的信息，并做一些值的装饰，例如 分片表需要替换表名。\npg_class 表\nhttps://opengauss.org/zh/docs/3.1.0/docs/Developerguide/PG_CLASS.html\n黄色表示 \\d 使用到的字段\npg_namespace 表\nhttps://opengauss.org/zh/docs/3.1.0/docs/Developerguide/PG_NAMESPACE.html\n关键问题及解决方法 查询语句中的函数无法下推，如何使用 通过 federation 注册函数解决 pg_table_is_visible(c.oid) mock 返回 true，收集数据时就只收集 true 的部分；\npg_get_userbyid mock 返回 ss 中配置的用户；\npg_class 数据量比较大，只收集 \\d 使用到的数据行内容。 查询中需要根据 pg_class 的 relnamespace 关联到 pg_namespace 中的 oid， 但是由于分布式系统，因此可能存在 pg_namespace oid 相同但是 nspname 却不同。 需要新建一张系统 oid 映射关系表，通过 ss 生成 id 映射不同实例的 oid，在表存储时，需要存储 ss 生成的 oid。（需要进一步设计）\n针对 \\d+ 是否能够支持 SELECT n.nspname as \"Schema\", c.relname as \"Name\", CASE c.relkind WHEN 'r' THEN 'table' WHEN 'v' THEN 'view' WHEN 'i' THEN 'index' WHEN 'I' THEN 'global partition index' WHEN 'S' THEN 'sequence' WHEN 'L' THEN 'large sequence' WHEN 'f' THEN 'foreign table' WHEN 'm' THEN 'materialized view' WHEN 'e' THEN 'stream' WHEN 'o' THEN 'contview' END as \"Type\", pg_catalog.pg_get_userbyid(c.relowner) as \"Owner\", -- 该值暂时无法支持显示，需要获取大小 pg_catalog.pg_size_pretty(pg_catalog.pg_table_size(c.oid)) as \"Size\", c.reloptions as \"Storage\", -- 该值依赖 pg_catalog.pg_description 表的收集以及 oid 的映射维护 -- select description from pg_catalog.pg_description where objoid = $1 and classoid = (select oid from pg_catalog.pg_class where relname = $2 and relnamespace = 11) and objsubid = 0 pg_catalog.obj_description(c.oid, 'pg_class') as \"Description\" FROM pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE c.relkind IN ('r','v','m','S','L','f','e','o','') AND n.nspname \u003c\u003e 'pg_catalog' AND n.nspname \u003c\u003e 'db4ai' AND n.nspname \u003c\u003e 'information_schema' AND n.nspname !~ '^pg_toast' AND c.relname not like 'matviewmap\\_%' AND c.relname not like 'mlog\\_%' AND pg_catalog.pg_table_is_visible(c.oid) ORDER BY 1,2; 附录 系统函数分析 pg_get_userbyid\n对应源码为\n/* ---------- * pg_get_userbyid - Get a user name by roleid and * fallback to 'unknown (OID=n)' * ---------- */ Datum pg_get_userbyid(PG_FUNCTION_ARGS) { Oid roleid = PG_GETARG_OID(0); Name result; HeapTuple roletup; Form_pg_authid role_rec; /* * Allocate space for the result */ result = (Name) palloc(NAMEDATALEN); memset(NameStr(*result), 0, NAMEDATALEN); /* * Get the pg_authid entry and print the result */ roletup = SearchSysCache1(AUTHOID, ObjectIdGetDatum(roleid)); if (HeapTupleIsValid(roletup)) { role_rec = (Form_pg_authid) GETSTRUCT(roletup); *result = role_rec-\u003erolname; ReleaseSysCache(roletup); } else sprintf(NameStr(*result), \"unknown (OID=%u)\", roleid); PG_RETURN_NAME(result); } 可以用以下语句获取\n\u003cstrong\u003eselect\u003c/strong\u003e oid,rolname \u003cstrong\u003efrom\u003c/strong\u003e pg_authid where oid = 1234 pg_table_is_visible(c.oid) 函数对应源码如下\n/* * RelationIsVisible * Determine whether a relation (identified by OID) is visible in the * current search path. Visible means \"would be found by searching * for the unqualified relation name\". */ bool RelationIsVisible(Oid relid) { HeapTuple reltup; Form_pg_class relform; Oid relnamespace; bool visible; reltup = SearchSysCache1(\u003cem\u003eRELOID\u003c/em\u003e, ObjectIdGetDatum(relid)); if (!HeapTupleIsValid(reltup)) elog(ERROR, \"cache lookup failed for relation %u\", relid); relform = (Form_pg_class) GETSTRUCT(reltup); recomputeNamespacePath(); /* * Quick check: if it ain't in the path at all, it ain't visible. Items in * the system namespace are surely in the path and so we needn't even do * list_member_oid() for them. */ relnamespace = relform-\u003erelnamespace; if (relnamespace != PG_CATALOG_NAMESPACE \u0026\u0026 !list_member_oid(activeSearchPath, relnamespace)) visible = false; else { /* * If it is in the path, it might still not be visible; it could be * hidden by another relation of the same name earlier in the path. So * we must do a slow check for conflicting relations. */ char *relname = NameStr(relform-\u003erelname); ListCell *l; visible = false; foreach(l, activeSearchPath) { Oid namespaceId = lfirst_oid(l); if (namespaceId == relnamespace) { /* Found it first in path */ visible = true; break; } if (OidIsValid(get_relname_relid(relname, namespaceId))) { /* Found something else first in path */ break; } } } ReleaseSysCache(reltup); return visible; } ","description":"","tags":null,"title":"ShardingSphere PostgreSQL openGauss \\d 支持方案","uri":"/posts/shardingsphere_sys_data_d/"},{"categories":null,"content":"构建 yat 下载源码\ngit clone https://gitee.com/opengauss/Yat.git 构建 yat\ncd Yat/yat-master chmod +x gradlew ./gradlew pack cd pkg chmod +x install ./install -F 根据源码中的 dockerFile 构建 dockerImage\n使用 yat 测试 测试 shardingSphere proxy 利用构建的 yat image 运行相关测试 需要挂在到对应目录\ndocker run --name yat0 -i -t -v /Users/chenchuxin/Documents/GitHub/Yat/openGaussBase:/root/openGaussBase -w /root/openGaussBase --entrypoint=bash --privileged=true yat-v1 修改 yat 项目 openGaussBase/conf 下的 configure.yml 文件\nyat.limit.case.size.max: '200K' yat.limit.case.count.max: 100000 yat.limit.case.depth.max: 10 yat.limit.case.name.pattern: .* 修改 yat 项目 openGaussBase/conf 下的 nodes.yml 文件\ndefault: host: 'host.docker.internal' db: url: 'jdbc:opengauss://host.docker.internal:3307/sharding_db?loggerLevel=OFF' driver: 'org.opengauss.Driver' username: 'root' password: 'root' port: 3307 name: 'sharding_db' ssh: port: 22 username: root password: '********' 创建 conf/env.sh\ntouch conf/env.sh 在 openGaussBase/schedule 目录创建 schedule.schd 文件，增加你需要测试的 case\ntest: SQL/DDL/view/Opengauss_Function_DDL_View_Case0034 进入 docker bash 模式 运行 yat suite\n[+] [2022-06-22 09:06:15] [05.394 s] [v] SQL/DDL/view/Opengauss_Function_DDL_View_Case0034 .... : ok ################# Testing Result 1/1 Using Time PT5.46011S At 2022-06-22 09:06:20 ################## Run test suite finished 也可能出现相关异常，可参考 https://gitee.com/opengauss/Yat/blob/master/yat-master/docs/index.md#yat-quick-start 来解决\n","description":"","tags":null,"title":"Add Yat Test for ShardingSphere","uri":"/posts/add-yat-test-for-shardingsphere/"},{"categories":null,"content":"https://zhuanlan.zhihu.com/p/515688555\nmac 开发环境启动 galaxysql https://hub.docker.com/r/polardbx/polardb-x\ndocker pull polardbx/polardb-x docker run -d --name some-dn-and-gms --env mode=dev -p 4886:4886 -p 32886:32886 polardbx/polardb-x docker exec -it 41d8a027 bash mysql -h127.0.0.1 -P4886 -uroot -padmin -D polardbx_meta_db_polardbx -e \"select passwd_enc from storage_info where inst_kind=2\" 获取密码后修改 server.properties\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 serverPort=8528 managerPort=3406 rpcPort=9090 charset=utf-8 processors=4 processorHandler=16 processorKillExecutor=128 timerExecutor=8 managerExecutor=256 serverExecutor=1024 idleTimeout= trustedIps=127.0.0.1 slowSqlTime=1000 maxConnection=20000 allowManagerLogin=1 allowCrossDbQuery=true galaxyXProtocol=1 metaDbAddr=127.0.0.1:4886 metaDbXprotoPort=32886 metaDbUser=my_polarx # 前文查看的存储节点密码 metaDbPasswd=qEJWtCdgsOIie4j4mKP2Bvg2dsFHzdIhTaqMiq86N1QQU1HHL7olKb60pxz5hp/4 #?? E2+jB0*0\u0026gM9)9$4+6)E4@1$lO9%G8+jA4_ metaDbName=polardbx_meta_db_polardbx instanceId=polardbx-polardbx 注释掉 CobarServer.java 中 tryStartCdcManager(); 代码\n启动配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003ccomponent name=\"ProjectRunConfigurationManager\"\u003e \u003cconfiguration default=\"false\" name=\"TddlLauncher\" type=\"Application\" factoryName=\"Application\" singleton=\"false\" nameIsGenerated=\"true\"\u003e \u003cenvs\u003e \u003cenv name=\"dnPasswordKey\" value=\"asdf1234ghjk5678\" /\u003e \u003c/envs\u003e \u003coption name=\"MAIN_CLASS_NAME\" value=\"com.alibaba.polardbx.server.TddlLauncher\" /\u003e \u003cmodule name=\"polardbx-server\" /\u003e \u003coption name=\"VM_PARAMETERS\" value=\"-Dserver.conf=$PROJECT_DIR$/polardbx-server/src/main/conf/server.properties\" /\u003e \u003cextension name=\"coverage\"\u003e \u003cpattern\u003e \u003coption name=\"PATTERN\" value=\"com.alibaba.polardbx.server.*\" /\u003e \u003coption name=\"ENABLED\" value=\"true\" /\u003e \u003c/pattern\u003e \u003c/extension\u003e \u003cmethod v=\"2\"\u003e \u003coption name=\"Make\" enabled=\"true\" /\u003e \u003c/method\u003e \u003c/configuration\u003e \u003c/component\u003e 连接 polar-dbx cn\nmysql -h127.0.0.1 -P8528 -upolardbx_root -p123456 polardb-x debug ddl create ddl 一直不能成功原来是因为，docker 镜像中没有启动 cdc，DDL 流程中涉及到 notify cdc，所以注释 CdcManager.notifyDdl 方法中的代码可以执行成功。 这篇文档写得挺好，说明了 ddl 执行的流程 https://zhuanlan.zhihu.com/p/515688555\n","description":"","tags":null,"title":"Polar Db","uri":"/posts/polar-db/"},{"categories":null,"content":"Step 1: 克隆项目\nStep 2: 添加新的远程仓库 为了修改他人 Fork 的仓库，你需要将其添加到自己的远程仓库列表中\n$ git remote add sirmin https://github.com/SirMin/shardingsphere.git 现在，当你执行 git remote -v 指令时，就可以看到他人 Fork 的仓库，出现在你的远程仓库列表中：\n% git remote -v origin\thttps://github.com/tuichenchuxin/shardingsphere.git (fetch) origin\thttps://github.com/tuichenchuxin/shardingsphere.git (push) sirmin\thttps://github.com/SirMin/shardingsphere.git (fetch) sirmin\thttps://github.com/SirMin/shardingsphere.git (push) upstream\thttps://github.com/apache/shardingsphere.git (fetch) upstream\thttps://github.com/apache/shardingsphere.git (push) Step 3: 拉取新的远程仓库\n$ git fetch sirmin Step 4: 切换到对应的分支 你需要确认一下，贡献者提出 Pull Request 时所用的分支（如果你不确定他们使用的哪个分支，请看 Pull Request 顶部的信息）：\n在本地，给该分支起一个不重复的名字，例如 EvanOne0616-patch，然后切换到贡献者提出 Pull Request 所用的分支：\n$ git checkout -b sirmin-patch sirmin/sirmin/resultSet Step 5: 提交修改，推送远程\n$ git commit -m \"Fix the wrong spelling of the word\" $ git push sirmin HEAD:sirmin/resultSet ","description":"","tags":null,"title":"How to Modify Pr","uri":"/posts/modifypr/"},{"categories":null,"content":"docker pull registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g docker run --privileged --restart=always --name oracle_11g -p 1521:1521 -d registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g docker exec -it 容器ID /bin/bash source /home/oracle/.bash_profile sqlplus nologconnect as sysdba 1 2 3 4 create user oracle identified by oracle#123; alter user system identified by system; alter user system identified by 123456; grant connect,resource,dba to oracle; 参考：https://baijiahao.baidu.com/s?id=1709232831349390844\u0026wfr=spider\u0026for=pc\n","description":"","tags":null,"title":"mac docker 安装 oracle 11g","uri":"/posts/installoracle11g/"},{"categories":null,"content":"Freemarker freemarker 是一款开源的模版引擎，可以基于模版方便的生成结果。 https://freemarker.apache.org/\nFreemarker 的使用 编写 ftl 模版 以生成 postgres 查询的 sql 语句为例 编写 delete.ftl 文件，${} 中的字段是参数\n1 DROP TABLE IF EXISTS ${schema}.${name}; 当然实际使用中的模版可能复杂的多，以部分创建表模版为例 我们可以在模版中使用 import 引入其它模版 使用 assign 设置变量 使用 if, list 等 使用 ?? 判断是否为空，使用 !false 如果为空，默认 false\n\u003c#import \"../../macro/constraints.ftl\" as CONSTRAINTS\u003e \u003c#assign with_clause = false\u003e \u003c#if fillfactor!false || parallel_workers!false || toast_tuple_target!false || (autovacuum_custom!false \u0026\u0026 add_vacuum_settings_in_sql!false) || autovacuum_enabled == 't' || autovacuum_enabled == 'f' || (toast_autovacuum!false \u0026\u0026 add_vacuum_settings_in_sql!false) || toast_autovacuum_enabled == 't' || toast_autovacuum_enabled == 'f' \u003e \u003c#assign with_clause = true\u003e \u003c/#if\u003e \u003c#list columns as c \u003e 其它模版使用可以参考 https://freemarker.apache.org/docs/dgui_template.html\njava 使用 freemarker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @NoArgsConstructor(access = AccessLevel.PRIVATE) public final class FreemarkerManager { private static final FreemarkerManager INSTANCE = new FreemarkerManager(); private final Configuration templateConfig = createTemplateConfiguration(); /** * Get freemarker manager instance. * * @return freemarker manager instance */ public static FreemarkerManager getInstance() { return INSTANCE; } @SneakyThrows private Configuration createTemplateConfiguration() { Configuration result = new Configuration(Configuration.VERSION_2_3_31); result.setDirectoryForTemplateLoading(new File(Objects.requireNonNull(FreemarkerManager.class.getClassLoader().getResource(\"template\")).getFile())); result.setDefaultEncoding(\"UTF-8\"); return result; } /** * Get sql from template. * * @param data data * @param path path * @return sql */ @SneakyThrows public static String getSqlFromTemplate(final Map\u003cString, Object\u003e data, final String path) { Template template = FreemarkerManager.getInstance().templateConfig.getTemplate(path); try (StringWriter result = new StringWriter()) { template.process(data, result); return result.toString(); } } } ","description":"","tags":null,"title":"Freemarker 的使用","uri":"/posts/use_free_marker/"},{"categories":null,"content":"下载源码 https://github.com/postgres/pgadmin4\n安装环境 brew install node brew install yarn cd runtime yarn install node_modules/nw/nwjs/nwjs.app/Contents/MacOS/nwjs . sudo mkdir \"/var/log/pgadmin\" sudo chmod a+wrx \"/var/log/pgadmin\" sudo mkdir \"/var/lib/pgadmin\" sudo chmod a+wrx \"/var/lib/pgadmin\" pip install --upgrade pip pip install psycopg2-binary make install-node 最后运行 pgAdmin4.py 过程中会有一些问题，参考 https://github.com/postgres/pgadmin4 readme. 和 stack overflow\n","description":"","tags":null,"title":"How To Debug PgAdmin4","uri":"/posts/howtodebugpgadmin4/"},{"categories":null,"content":"PgAmdin4 展示 DDL 语句 通过 PgAdmin4 可以获取 table 的 DDL 语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- Table: public.t_order_0 -- DROP TABLE IF EXISTS public.t_order_0; CREATE TABLE IF NOT EXISTS public.t_order_0 ( order_id integer NOT NULL, user_id integer NOT NULL, status character varying(45) COLLATE pg_catalog.\"default\", CONSTRAINT t_order_0_pkey PRIMARY KEY (order_id) ) TABLESPACE pg_default; ALTER TABLE IF EXISTS public.t_order_0 OWNER to postgres; COMMENT ON TABLE public.t_order_0 IS 'haha'; COMMENT ON COLUMN public.t_order_0.order_id IS 'haha'; PgAdmin4 是如何展示对应的 DDL 语句的呢 https://github.com/postgres/pgadmin4 翻阅源码发现 DDL 语句的展示，主要是通过以下步骤来获取 SQL 语句的。\n查询表基础信息（区分 pg 不同版本） 获取相关权限信息 查询列相关信息 检查 of_type 和 继承表，如果存在需要获取 获取该表的所有列信息 对列做格式化 查询 constriant 信息，并添加到 列上 检查 table is partitions 查询 index 信息 查询 ROW SECURITY POLICY 查询 Triggers 查询 Rules 相关代码如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def sql(self, gid, sid, did, scid, tid): \"\"\" This function will creates reverse engineered sql for the table object Args: gid: Server Group ID sid: Server ID did: Database ID scid: Schema ID tid: Table ID \"\"\" main_sql = [] status, res = self._fetch_table_properties(did, scid, tid) if not status: return res if len(res['rows']) == 0: return gone(gettext(self.not_found_error_msg())) data = res['rows'][0] return BaseTableView.get_reverse_engineered_sql( self, did=did, scid=scid, tid=tid, main_sql=main_sql, data=data, add_not_exists_clause=True) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_reverse_engineered_sql(self, **kwargs): \"\"\" This function will creates reverse engineered sql for the table object Args: kwargs \"\"\" did = kwargs.get('did') scid = kwargs.get('scid') tid = kwargs.get('tid') main_sql = kwargs.get('main_sql') data = kwargs.get('data') json_resp = kwargs.get('json_resp', True) diff_partition_sql = kwargs.get('diff_partition_sql', False) if_exists_flag = kwargs.get('add_not_exists_clause', False) # Table \u0026 Schema declaration so that we can use them in child nodes schema = data['schema'] table = data['name'] is_partitioned = 'is_partitioned' in data and data['is_partitioned'] # Get Reverse engineered sql for Table self._get_resql_for_table(did, scid, tid, data, json_resp, main_sql, add_not_exists_clause=if_exists_flag) # Get Reverse engineered sql for Table self._get_resql_for_index(did, tid, main_sql, json_resp, schema, table, add_not_exists_clause=if_exists_flag) # Get Reverse engineered sql for ROW SECURITY POLICY self._get_resql_for_row_security_policy(scid, tid, json_resp, main_sql, schema, table) # Get Reverse engineered sql for Triggers self._get_resql_for_triggers(tid, json_resp, main_sql, schema, table) # Get Reverse engineered sql for Compound Triggers self._get_resql_for_compound_triggers(tid, main_sql, schema, table) # Get Reverse engineered sql for Rules self._get_resql_for_rules(tid, main_sql, table, json_resp) # Get Reverse engineered sql for Partitions partition_main_sql = \"\" if is_partitioned: sql = render_template(\"/\".join([self.partition_template_path, self._NODES_SQL]), scid=scid, tid=tid) status, rset = self.conn.execute_2darray(sql) if not status: return internal_server_error(errormsg=rset) self._get_resql_for_partitions(data, rset, json_resp, diff_partition_sql, main_sql, did) sql = '\\n'.join(main_sql) if not json_resp: return sql, partition_main_sql return ajax_response(response=sql.strip('\\n')) pgAdmin 展示表结构反向 SQL 执行了哪些 SQL 语句呢？ table propeties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 SELECT rel.oid, rel.relname AS name, rel.reltablespace AS spcoid,rel.relacl AS relacl_str, (CASE WHEN length(spc.spcname::text) \u003e 0 OR rel.relkind = 'p' THEN spc.spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END) as spcname, (CASE rel.relreplident WHEN 'd' THEN 'default' WHEN 'n' THEN 'nothing' WHEN 'f' THEN 'full' WHEN 'i' THEN 'index' END) as replica_identity, (select nspname FROM pg_catalog.pg_namespace WHERE oid = 2200::oid ) as schema, pg_catalog.pg_get_userbyid(rel.relowner) AS relowner, rel.relkind, (CASE WHEN rel.relkind = 'p' THEN true ELSE false END) AS is_partitioned, rel.relhassubclass, rel.reltuples::bigint, des.description, con.conname, con.conkey, EXISTS(select 1 FROM pg_catalog.pg_trigger JOIN pg_catalog.pg_proc pt ON pt.oid=tgfoid AND pt.proname='logtrigger' JOIN pg_catalog.pg_proc pc ON pc.pronamespace=pt.pronamespace AND pc.proname='slonyversion' WHERE tgrelid=rel.oid) AS isrepl, (SELECT count(*) FROM pg_catalog.pg_trigger WHERE tgrelid=rel.oid AND tgisinternal = FALSE) AS triggercount, (SELECT ARRAY(SELECT CASE WHEN (nspname NOT LIKE 'pg\\_%') THEN pg_catalog.quote_ident(nspname)||'.'||pg_catalog.quote_ident(c.relname) ELSE pg_catalog.quote_ident(c.relname) END AS inherited_tables FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid ORDER BY inhseqno)) AS coll_inherits, (SELECT count(*) FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid) AS inherited_tables_cnt, (CASE WHEN rel.relpersistence = 'u' THEN true ELSE false END) AS relpersistence, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'fillfactor=([0-9]*)') AS fillfactor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'parallel_workers=([0-9]*)') AS parallel_workers, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'toast_tuple_target=([0-9]*)') AS toast_tuple_target, (substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS autovacuum_enabled, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS autovacuum_freeze_table_age, (substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS toast_autovacuum_enabled, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS toast_autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS toast_autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS toast_autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS toast_autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS toast_autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS toast_autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS toast_autovacuum_freeze_table_age, rel.reloptions AS reloptions, tst.reloptions AS toast_reloptions, rel.reloftype, CASE WHEN typ.typname IS NOT NULL THEN (select pg_catalog.quote_ident(nspname) FROM pg_catalog.pg_namespace WHERE oid = 2200::oid )||'.'||pg_catalog.quote_ident(typ.typname) ELSE typ.typname END AS typname, typ.typrelid AS typoid, rel.relrowsecurity as rlspolicy, rel.relforcerowsecurity as forcerlspolicy, (CASE WHEN rel.reltoastrelid = 0 THEN false ELSE true END) AS hastoasttable, (SELECT pg_catalog.array_agg(provider || '=' || label) FROM pg_catalog.pg_seclabels sl1 WHERE sl1.objoid=rel.oid AND sl1.objsubid=0) AS seclabels, (CASE WHEN rel.oid \u003c= 13756::oid THEN true ElSE false END) AS is_sys_table -- Added for partition table , (CASE WHEN rel.relkind = 'p' THEN pg_catalog.pg_get_partkeydef(16410::oid) ELSE '' END) AS partition_scheme FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=rel.oid AND des.objsubid=0 AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND NOT rel.relispartition AND rel.oid = 16410::oid ORDER BY rel.relname; 表总数 'SELECT COUNT(*)::text FROM public.t_order_1;' 权限 SELECT 'relacl' as deftype, COALESCE(gt.rolname, 'PUBLIC') grantee, g.rolname grantor, pg_catalog.array_agg(privilege_type) as privileges, pg_catalog.array_agg(is_grantable) as grantable FROM (SELECT d.grantee, d.grantor, d.is_grantable, CASE d.privilege_type WHEN 'CONNECT' THEN 'c' WHEN 'CREATE' THEN 'C' WHEN 'DELETE' THEN 'd' WHEN 'EXECUTE' THEN 'X' WHEN 'INSERT' THEN 'a' WHEN 'REFERENCES' THEN 'x' WHEN 'SELECT' THEN 'r' WHEN 'TEMPORARY' THEN 'T' WHEN 'TRIGGER' THEN 't' WHEN 'TRUNCATE' THEN 'D' WHEN 'UPDATE' THEN 'w' WHEN 'USAGE' THEN 'U' ELSE 'UNKNOWN' END AS privilege_type FROM (SELECT rel.relacl FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) acl, (SELECT (d).grantee AS grantee, (d).grantor AS grantor, (d).is_grantable AS is_grantable, (d).privilege_type AS privilege_type FROM (SELECT aclexplode(rel.relacl) as d FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) a ORDER BY privilege_type) d ) d LEFT JOIN pg_catalog.pg_roles g ON (d.grantor = g.oid) LEFT JOIN pg_catalog.pg_roles gt ON (d.grantee = gt.oid) GROUP BY g.rolname, gt.rolname reverse engine for table\nSELECT 'relacl' as deftype, COALESCE(gt.rolname, 'PUBLIC') grantee, g.rolname grantor, pg_catalog.array_agg(privilege_type) as privileges, pg_catalog.array_agg(is_grantable) as grantable FROM (SELECT d.grantee, d.grantor, d.is_grantable, CASE d.privilege_type WHEN 'CONNECT' THEN 'c' WHEN 'CREATE' THEN 'C' WHEN 'DELETE' THEN 'd' WHEN 'EXECUTE' THEN 'X' WHEN 'INSERT' THEN 'a' WHEN 'REFERENCES' THEN 'x' WHEN 'SELECT' THEN 'r' WHEN 'TEMPORARY' THEN 'T' WHEN 'TRIGGER' THEN 't' WHEN 'TRUNCATE' THEN 'D' WHEN 'UPDATE' THEN 'w' WHEN 'USAGE' THEN 'U' ELSE 'UNKNOWN' END AS privilege_type FROM (SELECT rel.relacl FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) acl, (SELECT (d).grantee AS grantee, (d).grantor AS grantor, (d).is_grantable AS is_grantable, (d).privilege_type AS privilege_type FROM (SELECT aclexplode(rel.relacl) as d FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND rel.oid = 16410::oid ) a ORDER BY privilege_type) d ) d LEFT JOIN pg_catalog.pg_roles g ON (d.grantor = g.oid) LEFT JOIN pg_catalog.pg_roles gt ON (d.grantee = gt.oid) GROUP BY g.rolname, gt.rolname 获取列\nSELECT att.attname as name, att.atttypid, att.attlen, att.attnum, att.attndims, att.atttypmod, att.attacl, att.attnotnull, att.attoptions, att.attstattarget, att.attstorage, att.attidentity, pg_catalog.pg_get_expr(def.adbin, def.adrelid) AS defval, pg_catalog.format_type(ty.oid,NULL) AS typname, pg_catalog.format_type(ty.oid,att.atttypmod) AS displaytypname, pg_catalog.format_type(ty.oid,att.atttypmod) AS cltype, CASE WHEN ty.typelem \u003e 0 THEN ty.typelem ELSE ty.oid END as elemoid, (SELECT nspname FROM pg_catalog.pg_namespace WHERE oid = ty.typnamespace) as typnspname, ty.typstorage AS defaultstorage, description, pi.indkey, (SELECT count(1) FROM pg_catalog.pg_type t2 WHERE t2.typname=ty.typname) \u003e 1 AS isdup, CASE WHEN length(coll.collname::text) \u003e 0 AND length(nspc.nspname::text) \u003e 0 THEN pg_catalog.concat(pg_catalog.quote_ident(nspc.nspname),'.',pg_catalog.quote_ident(coll.collname)) ELSE '' END AS collspcname, EXISTS(SELECT 1 FROM pg_catalog.pg_constraint WHERE conrelid=att.attrelid AND contype='f' AND att.attnum=ANY(conkey)) As is_fk, (SELECT pg_catalog.array_agg(provider || '=' || label) FROM pg_catalog.pg_seclabels sl1 WHERE sl1.objoid=att.attrelid AND sl1.objsubid=att.attnum) AS seclabels, (CASE WHEN (att.attnum \u003c 1) THEN true ElSE false END) AS is_sys_column, (CASE WHEN (att.attidentity in ('a', 'd')) THEN 'i' WHEN (att.attgenerated in ('s')) THEN 'g' ELSE 'n' END) AS colconstype, (CASE WHEN (att.attgenerated in ('s')) THEN pg_catalog.pg_get_expr(def.adbin, def.adrelid) END) AS genexpr, tab.relname as relname, (CASE WHEN tab.relkind = 'v' THEN true ELSE false END) AS is_view_only, seq.* FROM pg_catalog.pg_attribute att JOIN pg_catalog.pg_type ty ON ty.oid=atttypid LEFT OUTER JOIN pg_catalog.pg_attrdef def ON adrelid=att.attrelid AND adnum=att.attnum LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=att.attrelid AND des.objsubid=att.attnum AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN (pg_catalog.pg_depend dep JOIN pg_catalog.pg_class cs ON dep.classid='pg_class'::regclass AND dep.objid=cs.oid AND cs.relkind='S') ON dep.refobjid=att.attrelid AND dep.refobjsubid=att.attnum LEFT OUTER JOIN pg_catalog.pg_index pi ON pi.indrelid=att.attrelid AND indisprimary LEFT OUTER JOIN pg_catalog.pg_collation coll ON att.attcollation=coll.oid LEFT OUTER JOIN pg_catalog.pg_namespace nspc ON coll.collnamespace=nspc.oid LEFT OUTER JOIN pg_catalog.pg_sequence seq ON cs.oid=seq.seqrelid LEFT OUTER JOIN pg_catalog.pg_class tab on tab.oid = att.attrelid WHERE att.attrelid = 16410::oid AND att.attnum \u003e 0 AND att.attisdropped IS FALSE ORDER BY att.attnum; SELECT t.main_oid, pg_catalog.ARRAY_AGG(t.typname) as edit_types FROM (SELECT pc.castsource AS main_oid, pg_catalog.format_type(tt.oid,NULL) AS typname FROM pg_catalog.pg_type tt JOIN pg_catalog.pg_cast pc ON tt.oid=pc.casttarget WHERE pc.castsource IN (23,1043) AND pc.castcontext IN ('i', 'a') UNION SELECT tt.typbasetype AS main_oid, pg_catalog.format_type(tt.oid,NULL) AS typname FROM pg_catalog.pg_type tt WHERE tt.typbasetype IN (23,1043) ) t GROUP BY t.main_oid; SELECT 'attacl' as deftype, COALESCE(gt.rolname, 'PUBLIC') grantee, g.rolname grantor, pg_catalog.array_agg(privilege_type order by privilege_type) as privileges, pg_catalog.array_agg(is_grantable) as grantable FROM (SELECT d.grantee, d.grantor, d.is_grantable, CASE d.privilege_type WHEN 'CONNECT' THEN 'c' WHEN 'CREATE' THEN 'C' WHEN 'DELETE' THEN 'd' WHEN 'EXECUTE' THEN 'X' WHEN 'INSERT' THEN 'a' WHEN 'REFERENCES' THEN 'x' WHEN 'SELECT' THEN 'r' WHEN 'TEMPORARY' THEN 'T' WHEN 'TRIGGER' THEN 't' WHEN 'TRUNCATE' THEN 'D' WHEN 'UPDATE' THEN 'w' WHEN 'USAGE' THEN 'U' ELSE 'UNKNOWN' END AS privilege_type FROM (SELECT attacl FROM pg_catalog.pg_attribute att WHERE att.attrelid = 16410::oid AND att.attnum = 1::int ) acl, (SELECT (d).grantee AS grantee, (d).grantor AS grantor, (d).is_grantable AS is_grantable, (d).privilege_type AS privilege_type FROM (SELECT pg_catalog.aclexplode(attacl) as d FROM pg_catalog.pg_attribute att WHERE att.attrelid = 16410::oid AND att.attnum = 1::int) a) d ) d LEFT JOIN pg_catalog.pg_roles g ON (d.grantor = g.oid) LEFT JOIN pg_catalog.pg_roles gt ON (d.grantee = gt.oid) GROUP BY g.rolname, gt.rolname ORDER BY grantee SELECT cls.oid, cls.relname as name, indnkeyatts as col_count, CASE WHEN length(spcname::text) \u003e 0 THEN spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END as spcname, CASE contype WHEN 'p' THEN desp.description WHEN 'u' THEN desp.description WHEN 'x' THEN desp.description ELSE des.description END AS comment, condeferrable, condeferred, conislocal, substring(pg_catalog.array_to_string(cls.reloptions, ',') from 'fillfactor=([0-9]*)') AS fillfactor FROM pg_catalog.pg_index idx JOIN pg_catalog.pg_class cls ON cls.oid=indexrelid LEFT OUTER JOIN pg_catalog.pg_tablespace ta on ta.oid=cls.reltablespace LEFT JOIN pg_catalog.pg_depend dep ON (dep.classid = cls.tableoid AND dep.objid = cls.oid AND dep.refobjsubid = '0' AND dep.refclassid=(SELECT oid FROM pg_catalog.pg_class WHERE relname='pg_constraint') AND dep.deptype='i') LEFT OUTER JOIN pg_catalog.pg_constraint con ON (con.tableoid = dep.refclassid AND con.oid = dep.refobjid) LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=cls.oid AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_description desp ON (desp.objoid=con.oid AND desp.objsubid = 0 AND desp.classoid='pg_constraint'::regclass) WHERE indrelid = 16410::oid AND contype='u' ORDER BY cls.relname SELECT c.oid, conname as name, relname, nspname, description as comment, pg_catalog.pg_get_expr(conbin, conrelid, true) as consrc, connoinherit, NOT convalidated as convalidated, conislocal FROM pg_catalog.pg_constraint c JOIN pg_catalog.pg_class cl ON cl.oid=conrelid JOIN pg_catalog.pg_namespace nl ON nl.oid=relnamespace LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=c.oid AND des.classoid='pg_constraint'::regclass) WHERE contype = 'c' AND conrelid = 16410::oid SELECT cls.oid, cls.relname as name, indnkeyatts as col_count, amname, CASE WHEN length(spcname::text) \u003e 0 THEN spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END as spcname, CASE contype WHEN 'p' THEN desp.description WHEN 'u' THEN desp.description WHEN 'x' THEN desp.description ELSE des.description END AS comment, condeferrable, condeferred, substring(pg_catalog.array_to_string(cls.reloptions, ',') from 'fillfactor=([0-9]*)') AS fillfactor, pg_catalog.pg_get_expr(idx.indpred, idx.indrelid, true) AS indconstraint FROM pg_catalog.pg_index idx JOIN pg_catalog.pg_class cls ON cls.oid=indexrelid LEFT OUTER JOIN pg_catalog.pg_tablespace ta on ta.oid=cls.reltablespace JOIN pg_catalog.pg_am am ON am.oid=cls.relam LEFT JOIN pg_catalog.pg_depend dep ON (dep.classid = cls.tableoid AND dep.objid = cls.oid AND dep.refobjsubid = '0' AND dep.refclassid=(SELECT oid FROM pg_catalog.pg_class WHERE relname='pg_constraint') AND dep.deptype='i') LEFT OUTER JOIN pg_catalog.pg_constraint con ON (con.tableoid = dep.refclassid AND con.oid = dep.refobjid) LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=cls.oid AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_description desp ON (desp.objoid=con.oid AND desp.objsubid = 0 AND desp.classoid='pg_constraint'::regclass) WHERE indrelid = 16410::oid AND contype='x' ORDER BY cls.relname Table 结束，接下来是 index\nSELECT DISTINCT ON(cls.relname) cls.oid, cls.relname as name, (SELECT (CASE WHEN count(i.inhrelid) \u003e 0 THEN true ELSE false END) FROM pg_inherits i WHERE i.inhrelid = cls.oid) as is_inherited FROM pg_catalog.pg_index idx JOIN pg_catalog.pg_class cls ON cls.oid=indexrelid JOIN pg_catalog.pg_class tab ON tab.oid=indrelid LEFT OUTER JOIN pg_catalog.pg_tablespace ta on ta.oid=cls.reltablespace JOIN pg_catalog.pg_namespace n ON n.oid=tab.relnamespace JOIN pg_catalog.pg_am am ON am.oid=cls.relam LEFT JOIN pg_catalog.pg_depend dep ON (dep.classid = cls.tableoid AND dep.objid = cls.oid AND dep.refobjsubid = '0' AND dep.refclassid=(SELECT oid FROM pg_catalog.pg_class WHERE relname='pg_constraint') AND dep.deptype='i') LEFT OUTER JOIN pg_catalog.pg_constraint con ON (con.tableoid = dep.refclassid AND con.oid = dep.refobjid) WHERE indrelid = 16410::OID AND conname is NULL ORDER BY cls.relname ROW SECURITY POLICY\n'SELECT pl.oid AS oid, pl.polname AS name FROM pg_catalog.pg_policy pl WHERE pl.polrelid\t= 16410 ORDER BY pl.polname;' trigger\n1 2 3 4 5 SELECT t.oid, t.tgname as name, t.tgenabled AS is_enable_trigger FROM pg_catalog.pg_trigger t WHERE NOT tgisinternal AND tgrelid = 16410::OID ORDER BY tgname; rules\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT rw.oid AS oid, rw.rulename AS name, CASE WHEN rw.ev_enabled != \\'D\\' THEN True ELSE False END AS enabled, rw.ev_enabled AS is_enable_rule FROM pg_catalog.pg_rewrite rw WHERE rw.ev_class = 16410 ORDER BY rw.rulename ","description":"","tags":null,"title":"PgAmdin4 展示 DDL 语句逻辑分析","uri":"/posts/analysispgamdin4ddl/"},{"categories":null,"content":"获取 postgres 的建表语句的几种方法 使用 pg_dump 可以使用 pg_dump 直接查看建表语句 以本机 docker 的 postgres 为例\ndocker run -it --rm postgres pg_dump -h host.docker.internal -p 5432 -U postgres -d demo_ds_0 -s -t t_order_0 结果展示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 -- -- PostgreSQL database dump -- -- Dumped from database version 14.2 (Debian 14.2-1.pgdg110+1) -- Dumped by pg_dump version 14.2 (Debian 14.2-1.pgdg110+1) SET statement_timeout = 0; SET lock_timeout = 0; SET idle_in_transaction_session_timeout = 0; SET client_encoding = 'UTF8'; SET standard_conforming_strings = on; SELECT pg_catalog.set_config('search_path', '', false); SET check_function_bodies = false; SET xmloption = content; SET client_min_messages = warning; SET row_security = off; SET default_tablespace = ''; SET default_table_access_method = heap; -- -- Name: t_order_0; Type: TABLE; Schema: public; Owner: postgres -- CREATE TABLE public.t_order_0 ( order_id integer NOT NULL, user_id integer NOT NULL, status character varying(45) ); ALTER TABLE public.t_order_0 OWNER TO postgres; -- -- Name: TABLE t_order_0; Type: COMMENT; Schema: public; Owner: postgres -- COMMENT ON TABLE public.t_order_0 IS 'haha'; -- -- Name: COLUMN t_order_0.order_id; Type: COMMENT; Schema: public; Owner: postgres -- COMMENT ON COLUMN public.t_order_0.order_id IS 'haha'; -- -- Name: t_order_0 t_order_0_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres -- ALTER TABLE ONLY public.t_order_0 ADD CONSTRAINT t_order_0_pkey PRIMARY KEY (order_id); -- -- PostgreSQL database dump complete -- 使用自定义函数 创建函数如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 CREATE OR REPLACE FUNCTION tabledef(oid) RETURNS text LANGUAGE sql STRICT AS $$ /* snatched from https://github.com/filiprem/pg-tools */ WITH attrdef AS ( SELECT n.nspname, c.relname, pg_catalog.array_to_string(c.reloptions || array(select 'toast.' || x from pg_catalog.unnest(tc.reloptions) x), ', ') as relopts, c.relpersistence, a.attnum, a.attname, pg_catalog.format_type(a.atttypid, a.atttypmod) as atttype, (SELECT substring(pg_catalog.pg_get_expr(d.adbin, d.adrelid, true) for 128) FROM pg_catalog.pg_attrdef d WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum AND a.atthasdef) as attdefault, a.attnotnull, (SELECT c.collname FROM pg_catalog.pg_collation c, pg_catalog.pg_type t WHERE c.oid = a.attcollation AND t.oid = a.atttypid AND a.attcollation \u003c\u003e t.typcollation) as attcollation, a.attidentity, a.attgenerated FROM pg_catalog.pg_attribute a JOIN pg_catalog.pg_class c ON a.attrelid = c.oid JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid LEFT JOIN pg_catalog.pg_class tc ON (c.reltoastrelid = tc.oid) WHERE a.attrelid = $1 AND a.attnum \u003e 0 AND NOT a.attisdropped ORDER BY a.attnum ), coldef AS ( SELECT attrdef.nspname, attrdef.relname, attrdef.relopts, attrdef.relpersistence, pg_catalog.format( '%I %s%s%s%s%s', attrdef.attname, attrdef.atttype, case when attrdef.attcollation is null then '' else pg_catalog.format(' COLLATE %I', attrdef.attcollation) end, case when attrdef.attnotnull then ' NOT NULL' else '' end, case when attrdef.attdefault is null then '' else case when attrdef.attgenerated = 's' then pg_catalog.format(' GENERATED ALWAYS AS (%s) STORED', attrdef.attdefault) when attrdef.attgenerated \u003c\u003e '' then ' GENERATED AS NOT_IMPLEMENTED' else pg_catalog.format(' DEFAULT %s', attrdef.attdefault) end end, case when attrdef.attidentity\u003c\u003e'' then pg_catalog.format(' GENERATED %s AS IDENTITY', case attrdef.attidentity when 'd' then 'BY DEFAULT' when 'a' then 'ALWAYS' else 'NOT_IMPLEMENTED' end) else '' end ) as col_create_sql FROM attrdef ORDER BY attrdef.attnum ), tabdef AS ( SELECT coldef.nspname, coldef.relname, coldef.relopts, coldef.relpersistence, string_agg(coldef.col_create_sql, E',\\n ') as cols_create_sql FROM coldef GROUP BY coldef.nspname, coldef.relname, coldef.relopts, coldef.relpersistence ) SELECT format( 'CREATE%s TABLE %I.%I%s%s%s;', case tabdef.relpersistence when 't' then ' TEMP' when 'u' then ' UNLOGGED' else '' end, tabdef.nspname, tabdef.relname, coalesce( (SELECT format(E'\\n PARTITION OF %I.%I %s\\n', pn.nspname, pc.relname, pg_get_expr(c.relpartbound, c.oid)) FROM pg_class c JOIN pg_inherits i ON c.oid = i.inhrelid JOIN pg_class pc ON pc.oid = i.inhparent JOIN pg_namespace pn ON pn.oid = pc.relnamespace WHERE c.oid = $1), format(E' (\\n %s\\n)', tabdef.cols_create_sql) ), case when tabdef.relopts \u003c\u003e '' then format(' WITH (%s)', tabdef.relopts) else '' end, coalesce(E'\\nPARTITION BY '||pg_get_partkeydef($1), '') ) as table_create_sql FROM tabdef $$; 通过 pgAdmin4 获取 抓包后，发现 pgAdmin4 实际查询的 sql 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 SELECT rel.oid, rel.relname AS name, rel.reltablespace AS spcoid,rel.relacl AS relacl_str, (CASE WHEN length(spc.spcname::text) \u003e 0 OR rel.relkind = 'p' THEN spc.spcname ELSE (SELECT sp.spcname FROM pg_catalog.pg_database dtb JOIN pg_catalog.pg_tablespace sp ON dtb.dattablespace=sp.oid WHERE dtb.oid = 16384::oid) END) as spcname, (CASE rel.relreplident WHEN 'd' THEN 'default' WHEN 'n' THEN 'nothing' WHEN 'f' THEN 'full' WHEN 'i' THEN 'index' END) as replica_identity, (select nspname FROM pg_catalog.pg_namespace WHERE oid = 2200::oid ) as schema, pg_catalog.pg_get_userbyid(rel.relowner) AS relowner, rel.relkind, (CASE WHEN rel.relkind = 'p' THEN true ELSE false END) AS is_partitioned, rel.relhassubclass, rel.reltuples::bigint, des.description, con.conname, con.conkey, EXISTS(select 1 FROM pg_catalog.pg_trigger JOIN pg_catalog.pg_proc pt ON pt.oid=tgfoid AND pt.proname='logtrigger' JOIN pg_catalog.pg_proc pc ON pc.pronamespace=pt.pronamespace AND pc.proname='slonyversion' WHERE tgrelid=rel.oid) AS isrepl, (SELECT count(*) FROM pg_catalog.pg_trigger WHERE tgrelid=rel.oid AND tgisinternal = FALSE) AS triggercount, (SELECT ARRAY(SELECT CASE WHEN (nspname NOT LIKE 'pg\\_%') THEN pg_catalog.quote_ident(nspname)||'.'||pg_catalog.quote_ident(c.relname) ELSE pg_catalog.quote_ident(c.relname) END AS inherited_tables FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid ORDER BY inhseqno)) AS coll_inherits, (SELECT count(*) FROM pg_catalog.pg_inherits i JOIN pg_catalog.pg_class c ON c.oid = i.inhparent JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace WHERE i.inhrelid = rel.oid) AS inherited_tables_cnt, (CASE WHEN rel.relpersistence = 'u' THEN true ELSE false END) AS relpersistence, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'fillfactor=([0-9]*)') AS fillfactor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'parallel_workers=([0-9]*)') AS parallel_workers, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'toast_tuple_target=([0-9]*)') AS toast_tuple_target, (substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS autovacuum_enabled, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(rel.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS autovacuum_freeze_table_age, (substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_enabled=([a-z|0-9]*)'))::BOOL AS toast_autovacuum_enabled, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_threshold=([0-9]*)') AS toast_autovacuum_vacuum_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_vacuum_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_threshold=([0-9]*)') AS toast_autovacuum_analyze_threshold, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_analyze_scale_factor=([0-9]*[.]?[0-9]*)') AS toast_autovacuum_analyze_scale_factor, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_delay=([0-9]*)') AS toast_autovacuum_vacuum_cost_delay, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_vacuum_cost_limit=([0-9]*)') AS toast_autovacuum_vacuum_cost_limit, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_min_age=([0-9]*)') AS toast_autovacuum_freeze_min_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_max_age=([0-9]*)') AS toast_autovacuum_freeze_max_age, substring(pg_catalog.array_to_string(tst.reloptions, ',') FROM 'autovacuum_freeze_table_age=([0-9]*)') AS toast_autovacuum_freeze_table_age, rel.reloptions AS reloptions, tst.reloptions AS toast_reloptions, rel.reloftype, CASE WHEN typ.typname IS NOT NULL THEN (select pg_catalog.quote_ident(nspname) FROM pg_catalog.pg_namespace WHERE oid = 2200::oid )||'.'||pg_catalog.quote_ident(typ.typname) ELSE typ.typname END AS typname, typ.typrelid AS typoid, rel.relrowsecurity as rlspolicy, rel.relforcerowsecurity as forcerlspolicy, (CASE WHEN rel.reltoastrelid = 0 THEN false ELSE true END) AS hastoasttable, (SELECT pg_catalog.array_agg(provider || '=' || label) FROM pg_catalog.pg_seclabels sl1 WHERE sl1.objoid=rel.oid AND sl1.objsubid=0) AS seclabels, (CASE WHEN rel.oid \u003c= 13756::oid THEN true ElSE false END) AS is_sys_table -- Added for partition table , (CASE WHEN rel.relkind = 'p' THEN pg_catalog.pg_get_partkeydef(16396::oid) ELSE '' END) AS partition_scheme FROM pg_catalog.pg_class rel LEFT OUTER JOIN pg_catalog.pg_tablespace spc on spc.oid=rel.reltablespace LEFT OUTER JOIN pg_catalog.pg_description des ON (des.objoid=rel.oid AND des.objsubid=0 AND des.classoid='pg_class'::regclass) LEFT OUTER JOIN pg_catalog.pg_constraint con ON con.conrelid=rel.oid AND con.contype='p' LEFT OUTER JOIN pg_catalog.pg_class tst ON tst.oid = rel.reltoastrelid LEFT JOIN pg_catalog.pg_type typ ON rel.reloftype=typ.oid WHERE rel.relkind IN ('r','s','t','p') AND rel.relnamespace = 2200::oid AND NOT rel.relispartition AND rel.oid = 16396::oid ORDER BY rel.relname; https://github.com/postgres/pgadmin4\n","description":"","tags":null,"title":"How to get postgres create table sql","uri":"/posts/get_postgres_create_table_sql/"},{"categories":null,"content":"EventBus 的使用及注意点 使用 创建全局实例 1 static final EventBus INSTANCE = new EventBus(); 将含有 @Subscribe 的方法注册到全局实例上 1 INSTANCE.register(this); 发送 event 1 INSTANCE.post(event); 流程分析 采用上述方式时有以下几个注意点\n发送事件并且接受后处理事件是同步执行的，即同一个线程执行 如果在接受事件方法中有嵌套发送事件，那么该嵌套发送的事件不会立即执行，会等到第一个事件的接收方法完成后，再执行第二个事件。 EventBus 调用流程分析 创建 EventBus 实例 将订阅者注册到 EventBus 实例上 创建 EventBus 实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public EventBus() { this(\"default\"); } /** * Creates a new EventBus with the given {@code identifier}. * * @param identifier a brief name for this bus, for logging purposes. Should be a valid Java * identifier. */ public EventBus(String identifier) { this( identifier, // 同步执行器 MoreExecutors.directExecutor(), Dispatcher.perThreadDispatchQueue(), LoggingHandler.INSTANCE); } 1 2 3 4 5 6 7 8 9 10 11 12 private static final class PerThreadQueuedDispatcher extends Dispatcher { // This dispatcher matches the original dispatch behavior of EventBus. /** Per-thread queue of events to dispatch. */ private final ThreadLocal\u003cQueue\u003cEvent\u003e\u003e queue = new ThreadLocal\u003cQueue\u003cEvent\u003e\u003e() { @Override protected Queue\u003cEvent\u003e initialValue() { return Queues.newArrayDeque(); } }; 注册 EventBus 订阅者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 /** * Registers all subscriber methods on {@code object} to receive events. * * @param object object whose subscriber methods should be registered. */ public void register(Object object) { subscribers.register(object); } /** Registers all subscriber methods on the given listener object. */ void register(Object listener) { Multimap\u003cClass\u003c?\u003e, Subscriber\u003e listenerMethods = findAllSubscribers(listener); for (Entry\u003cClass\u003c?\u003e, Collection\u003cSubscriber\u003e\u003e entry : listenerMethods.asMap().entrySet()) { Class\u003c?\u003e eventType = entry.getKey(); Collection\u003cSubscriber\u003e eventMethodsInListener = entry.getValue(); CopyOnWriteArraySet\u003cSubscriber\u003e eventSubscribers = subscribers.get(eventType); if (eventSubscribers == null) { CopyOnWriteArraySet\u003cSubscriber\u003e newSet = new CopyOnWriteArraySet\u003c\u003e(); eventSubscribers = MoreObjects.firstNonNull(subscribers.putIfAbsent(eventType, newSet), newSet); } eventSubscribers.addAll(eventMethodsInListener); } } /** * Returns all subscribers for the given listener grouped by the type of event they subscribe to. */ private Multimap\u003cClass\u003c?\u003e, Subscriber\u003e findAllSubscribers(Object listener) { Multimap\u003cClass\u003c?\u003e, Subscriber\u003e methodsInListener = HashMultimap.create(); Class\u003c?\u003e clazz = listener.getClass(); for (Method method : getAnnotatedMethods(clazz)) { Class\u003c?\u003e[] parameterTypes = method.getParameterTypes(); Class\u003c?\u003e eventType = parameterTypes[0]; methodsInListener.put(eventType, Subscriber.create(bus, listener, method)); } return methodsInListener; } /** Creates a {@code Subscriber} for {@code method} on {@code listener}. */ static Subscriber create(EventBus bus, Object listener, Method method) { return isDeclaredThreadSafe(method) ? new Subscriber(bus, listener, method) // 调用方法采用 synchronized : new SynchronizedSubscriber(bus, listener, method); } 发送 event 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 /** * Posts an event to all registered subscribers. This method will return successfully after the * event has been posted to all subscribers, and regardless of any exceptions thrown by * subscribers. * * \u003cp\u003eIf no subscribers have been subscribed for {@code event}'s class, and {@code event} is not * already a {@link DeadEvent}, it will be wrapped in a DeadEvent and reposted. * * @param event event to post. */ public void post(Object event) { Iterator\u003cSubscriber\u003e eventSubscribers = subscribers.getSubscribers(event); if (eventSubscribers.hasNext()) { dispatcher.dispatch(event, eventSubscribers); } else if (!(event instanceof DeadEvent)) { // the event had no subscribers and was not itself a DeadEvent post(new DeadEvent(this, event)); } } // 这里需要注意，如果当前线程在调用的 post 方法中，嵌套调用 post，第二个 post方法不会立刻执行，而是会加入 队列中，等到队列中第一个任务处理完，才会继续处理。 @Override void dispatch(Object event, Iterator\u003cSubscriber\u003e subscribers) { checkNotNull(event); checkNotNull(subscribers); Queue\u003cEvent\u003e queueForThread = queue.get(); queueForThread.offer(new Event(event, subscribers)); if (!dispatching.get()) { dispatching.set(true); try { Event nextEvent; while ((nextEvent = queueForThread.poll()) != null) { while (nextEvent.subscribers.hasNext()) { nextEvent.subscribers.next().dispatchEvent(nextEvent.event); } } } finally { dispatching.remove(); queue.remove(); } } } ","description":"","tags":null,"title":"guava EventBus 使用以及注意点","uri":"/posts/second/"},{"categories":null,"content":"背景 Apache ShardingSphere 基于用户的实际使用场景，为用户打造了多种实用功能，包括数据分片、读写分离等。在数据分片功能中，Apache ShardingSphere 提供了标准分片、复合分片等多种实用的分片策略，在各种分片策略中，用户又可以配置相关分片算法，从而解决数据分片的问题。在读写分离功能中，ShardingSphere 为用户提供了静态和动态的两种读写分离类型以及丰富的负载均衡算法以满足用户实际需求。 可以看到 ShardingSphere 的分片和读写分离功能已经非常丰富，不过用户的真实使用场景是千变万化的。以多租户场景为例，用户期望按照登录账号所属租户进行分片，但是租户信息却并不是存在于每条业务 SQL 中，这时从 SQL 中提取分片字段的算法将无法发挥作用。再以读写分离为例，大部分场景下用户都希望能够将查询操作路由到从库上执行，但是在某些实时性要求很高的场景下，用户希望将 SQL 强制路由到主库执行，这时读写分离就无法满足业务要求。 基于以上痛点 Apache ShardingSphere 为用户提供了 Hint 功能，用户可以结合实际业务场景，利用 SQL 外部的逻辑进行强制路由或者分片。目前 ShardingSphere 为用户提供了两种 Hint 方式，一种通过 Java API 手动编程，利用 HintManager 进行强制路由和分片，这种方式对采用 JDBC 编程的应用非常友好，只需要少量的代码编写，就能够轻松实现不依赖 SQL 的分片或者强制路由功能。另外一种方式对于不懂开发的 DBA 而言更加友好，ShardingSphere 基于分布式 SQL 提供的使用方式，利用 SQL HINT 和 DistSQL HINT， 为用户提供了无需编码就能实现的分片和强制路由功能。接下来，让我们一起了解下这两种使用方式。\n基于 HintManager 的手动编程 ShardingSphere 主要通过 HintManager 对象来实现强制路由和分片的功能。利用 HintManager，用户的分片将不用再依赖 SQL。它可以极大地扩展用户的使用场景，让用户可以更加灵活地进行数据分片或者强制路由。目前通过 HintManager，用户可以配合 ShardingSphere 内置的或者自定义的 Hint 算法实现分片功能，还可以通过设置指定数据源或者强制主库读写，实现强制路由功能。在学习 HintManager 的使用之前，让我们先来简单地了解一下它的实现原理，这有助于我们更好地使用它。\nHintManager 实现原理 其实通过查看 HintManager 代码，我们可以快速地了解它的原理。\n1 2 3 4 5 @NoArgsConstructor(access = AccessLevel.PRIVATE) public final class HintManager implements AutoCloseable { private static final ThreadLocal\u003cHintManager\u003e HINT_MANAGER_HOLDER = new ThreadLocal\u003c\u003e(); } 正如你所看到的，ShardingSphere 通过 ThreadLocal 来实现 HintManager 的功能，只要在同一个线程中，用户的分片设置都会得以保留。因此，只要用户在执行 SQL 之前调用 HintManager 相关功能，ShardingSphere 就能在当前线程中获取用户设置的分片或强制路由条件，从而进行分片或者路由操作。了解了 HintManager 的原理之后，让我们一起来学习一下它的使用。\nHintManager 的使用 使用 Hint 分片 Hint 分片算法需要用户实现 org.apache.shardingsphere.sharding.api.sharding.hint.HintShardingAlgorithm 接口。 Apache ShardingSphere 在进行路由时，将会从 HintManager 中获取分片值进行路由操作。\n参考配置如下： rules: - !SHARDING tables: t_order: actualDataNodes: demo_ds_${0..1}.t_order_${0..1} databaseStrategy: hint: algorithmClassName: xxx.xxx.xxx.HintXXXAlgorithm tableStrategy: hint: algorithmClassName: xxx.xxx.xxx.HintXXXAlgorithm defaultTableStrategy: none: defaultKeyGenerateStrategy: type: SNOWFLAKE column: order_id props: sql-show: true 获取 HintManager 实例 HintManager hintManager = HintManager.getInstance();\n添加分片键 使用 hintManager.addDatabaseShardingValue 来添加数据源分片键值。 使用 hintManager.addTableShardingValue 来添加表分片键值。 分库不分表情况下，强制路由至某一个分库时，可使用 hintManager.setDatabaseShardingValue 方式添加分片。 清除分片键值 分片键值保存在 ThreadLocal 中，所以需要在操作结束时调用 hintManager.close() 来清除 ThreadLocal 中的内容。 完整代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.addDatabaseShardingValue(\"t_order\", 1); hintManager.addTableShardingValue(\"t_order\", 2); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.setDatabaseShardingValue(3); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } 使用 Hint 强制主库路由 获取 HintManager 与基于 Hint 的数据分片相同。\n设置主库路由 使用 hintManager.setWriteRouteOnly 设置主库路由。 清除分片键值 与基于 Hint 的数据分片相同。\n完整代码示例 1 2 3 4 5 6 7 8 9 10 11 String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.setWriteRouteOnly(); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } 使用 Hint 路由至指定数据库 获取 HintManager 与基于 Hint 的数据分片相同。\n设置路由至指定数据库 使用 hintManager.setDataSourceName 设置数据库名称。 完整代码示例 1 2 3 4 5 6 7 8 9 10 11 String sql = \"SELECT * FROM t_order\"; try (HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement preparedStatement = conn.prepareStatement(sql)) { hintManager.setDataSourceName(\"ds_0\"); try (ResultSet rs = preparedStatement.executeQuery()) { while (rs.next()) { // ... } } } 清除强制路由值 与基于 Hint 的数据分片相同。\n在了解了基于 HintManager 的手动编程方式之后，让我们一起来了解 ShardingSphere 基于分布式 SQL 提供的另一种 Hint 的解决方案。\n基于分布式 SQL 的 Hint Apache ShardingSphere 的分布式 SQL HINT 主要由两种功能组成，一种叫做 SQL HINT，即基于 SQL 注释的方式提供的功能，另外一种是通过 DistSQL 实现的作用于 HintManager 的功能。\nSQL HINT SQL HINT 就是通过在 SQL 语句上增加注释，从而实现强制路由的一种 Hint 方式。它降低了用户改造代码的成本，同时完全脱离了 Java API 的限制，不仅可以在 ShardingSphere-JDBC 中使用，也可以直接在 ShardingSphere-Proxy 上使用。 以下面 SQL 为例，即使用户配置了针对 t_order 的相关分片算法，该 SQL 也会直接在数据库 ds_0 上原封不动地执行，并返回执行结果。\n1 2 /* ShardingSphere hint: dataSourceName=ds_0 */ SELECT * FROM t_order; 通过注释的方式我们可以方便地将 SQL 直接送达指定数据库执行而无视其它分片逻辑。以多租户场景为例，用户不用再配置复杂的分库逻辑，也无需改造业务逻辑，只需要将指定库添加到注释信息中即可。在了解了 SQL HINT 的基本使用之后，让我们一起来了解一下 SQL HINT 的实现原理。\nSQL HINT 的实现原理 其实了解 Apache ShardingSphere 的读者朋友们一定对 SQL 解析引擎不会感到陌生。SQL HINT 实现的第一步就是提取 SQL 中的注释信息。利用 antlr4 的通道功能，可以将 SQL 中的注释信息单独送至特定的隐藏通道，ShardingSphere 也正是利用该功能，在生成解析结果的同时，将隐藏通道中的注释信息一并提取出来了。具体实现如下方代码所示。\n将 SQL 中的注释送入隐藏通道。 lexer grammar Comments; import Symbol; BLOCK_COMMENT: '/*' .*? '*/' -\u003e channel(HIDDEN); INLINE_COMMENT: (('-- ' | '#') ~[\\r\\n]* ('\\r'? '\\n' | EOF) | '--' ('\\r'? '\\n' | EOF)) -\u003e channel(HIDDEN); 访问语法树后增加对于注释信息的提取： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public \u003cT\u003e T visit(final ParseContext parseContext) { ParseTreeVisitor\u003cT\u003e visitor = SQLVisitorFactory.newInstance(databaseType, visitorType, SQLVisitorRule.valueOf(parseContext.getParseTree().getClass()), props); T result = parseContext.getParseTree().accept(visitor); appendSQLComments(parseContext, result); return result; } private \u003cT\u003e void appendSQLComments(final ParseContext parseContext, final T visitResult) { if (!parseContext.getHiddenTokens().isEmpty() \u0026\u0026 visitResult instanceof AbstractSQLStatement) { Collection\u003cCommentSegment\u003e commentSegments = parseContext.getHiddenTokens().stream().map(each -\u003e new CommentSegment(each.getText(), each.getStartIndex(), each.getStopIndex())) .collect(Collectors.toList()); ((AbstractSQLStatement) visitResult).getCommentSegments().addAll(commentSegments); } } 提取出用户 SQL 中的注释信息之后，我们就需要根据注释信息来进行相关强制路由了。既然是路由，那么自然就需要使用 Apache ShardingSphere 的路由引擎，我们在路由引擎上做了一些针对 HINT 的改造。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public RouteContext route(final LogicSQL logicSQL, final ShardingSphereMetaData metaData) { RouteContext result = new RouteContext(); Optional\u003cString\u003e dataSourceName = findDataSourceByHint(logicSQL.getSqlStatementContext(), metaData.getResource().getDataSources()); if (dataSourceName.isPresent()) { result.getRouteUnits().add(new RouteUnit(new RouteMapper(dataSourceName.get(), dataSourceName.get()), Collections.emptyList())); return result; } for (Entry\u003cShardingSphereRule, SQLRouter\u003e entry : routers.entrySet()) { if (result.getRouteUnits().isEmpty()) { result = entry.getValue().createRouteContext(logicSQL, metaData, entry.getKey(), props); } else { entry.getValue().decorateRouteContext(result, logicSQL, metaData, entry.getKey(), props); } } if (result.getRouteUnits().isEmpty() \u0026\u0026 1 == metaData.getResource().getDataSources().size()) { String singleDataSourceName = metaData.getResource().getDataSources().keySet().iterator().next(); result.getRouteUnits().add(new RouteUnit(new RouteMapper(singleDataSourceName, singleDataSourceName), Collections.emptyList())); } return result; } ShardingSphere 首先发现了符合定义的 SQL 注释，再经过基本的校验之后，就会直接返回用户指定的路由结果，从而实现强制路由功能。在了解了 SQL HINT 的基本原理之后，让我们一起学习如何使用 SQL HINT。\n如何使用 SQL HINT SQL HINT 的使用非常简单，无论是 ShardingSphere-JDBC 还是 ShardingSphere-Porxy，都可以使用。 第一步打开注释解析开关。将 sqlCommentParseEnabled 设置为 true。 第二步在 SQL 上增加注释即可。目前 SQL HINT 支持指定数据源路由和主库路由。\n指定数据源路由：目前只支持路由至一个数据源。 注释格式暂时只支持/* /，内容需要以ShardingSphere hint:开始，属性名为 dataSourceName。 / ShardingSphere hint: dataSourceName=ds_0 */ SELECT * FROM t_order;\n主库路由：注释格式暂时只支持/* /，内容需要以ShardingSphere hint:开始，属性名为 writeRouteOnly。 / ShardingSphere hint: writeRouteOnly=true */ SELECT * FROM t_order;\nDistSQL HINT Apache ShardingSphere 的 DistSQL 也提供了 Hint 相关功能，让用户可以通过 ShardingSphere-Proxy 来实现分片和强制路由功能。\nDistSQL HINT 的实现原理 同前文一致，在学习使用 DistSQL HINT 功能之前，让我们一起来了解一下 DistSQL Hint 的实现原理。DistSQL HINT 的实现原理非常简单，其实就是通过操作 HintManager 实现的 HINT 功能。以读写分离 Hint 为例，当用户通过 ShardingSphere-Proxy 执行以下 SQL 时，其实 ShardingSphere 内部对 SQL 做了如下方代码所示的操作。 – 强制主库读写\n1 set readwrite_splitting hint source = write 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @RequiredArgsConstructor public final class SetReadwriteSplittingHintExecutor extends AbstractHintUpdateExecutor\u003cSetReadwriteSplittingHintStatement\u003e { private final SetReadwriteSplittingHintStatement sqlStatement; @Override public ResponseHeader execute() { HintSourceType sourceType = HintSourceType.typeOf(sqlStatement.getSource()); switch (sourceType) { case AUTO: HintManagerHolder.get().setReadwriteSplittingAuto(); break; case WRITE: HintManagerHolder.get().setWriteRouteOnly(); break; default: break; } return new UpdateResponseHeader(new EmptyStatement()); } } @NoArgsConstructor(access = AccessLevel.PRIVATE) public final class HintManagerHolder { private static final ThreadLocal\u003cHintManager\u003e HINT_MANAGER_HOLDER = new ThreadLocal\u003c\u003e(); /** * Get an instance for {@code HintManager} from {@code ThreadLocal},if not exist,then create new one. * * @return hint manager */ public static HintManager get() { if (HINT_MANAGER_HOLDER.get() == null) { HINT_MANAGER_HOLDER.set(HintManager.getInstance()); } return HINT_MANAGER_HOLDER.get(); } /** * remove {@code HintManager} from {@code ThreadLocal}. */ public static void remove() { HINT_MANAGER_HOLDER.remove(); } } 用户执行 SQL 之后，DistSQL 解析引擎会首先识别出该 SQL 是读写分离 Hint 的 SQL，同时会提取出用户想要自动路由或者强制到主库的字段。之后它会采用 SetReadwriteSplittingHintExecutor 执行器去执行 SQL，从而将正确操作设置到 HintManager 中，进而实现强制路由主库的功能。\nDistSQL HINT 的使用 下表为大家展示了 DistSQL Hint 的相关语法。\n语句 说明 示例 set readwrite_splitting hint source = [auto / write] 针对当前连接，设置读写分离的路由策略（自动路由或强制到写库） set readwrite_splitting hint source = write set sharding hint database_value = yy 针对当前连接，设置 hint 仅对数据库分片有效，并添加分片值，yy：数据库分片值 set sharding hint database_value = 100 add sharding hint database_value xx = yy 针对当前连接，为表 xx 添加分片值 yy，xx：逻辑表名称，yy：数据库分片值 add sharding hint database_value t_order= 100 add sharding hint table_value xx = yy 针对当前连接，为表 xx 添加分片值 yy，xx：逻辑表名称，yy：表分片值 add sharding hint table_value t_order = 100 clear hint 针对当前连接，清除 hint 所有设置 clear hint clear [sharding hint / readwrite_splitting hint] 针对当前连接，清除 sharding 或 readwrite_splitting 的 hint 设置 clear readwrite_splitting hint show [sharding / readwrite_splitting] hint status 针对当前连接，查询 sharding 或 readwrite_splitting 的 hint 设置 show readwrite_splitting hint status 本文详细介绍了 Hint 使用的两种方式以及基本原理，相信通过本文，读者朋友们对 Hint 都有了一些基本了解了，大家可以根据自己的需求来选择使用合适的方式。如果在使用过程中遇到任何问题，或者有任何建议想法，都欢迎来社区反馈。\n","description":"","tags":null,"title":"ShardingSphere Hint 实用指南","uri":"/posts/my-first-post/"}]
